{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/samova/lcances/.miniconda3/envs/pytorch-dev/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SSL.util.model_loader import load_model\n",
    "from SSL.util.loaders import load_dataset, load_optimizer, load_callbacks, load_preprocesser\n",
    "from SSL.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from SSL.util.utils import reset_seed, get_datetime, track_maximum, DotDict\n",
    "\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.dataset_loader.audioset import Audioset, ChunkAlignSampler, _split_s_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = \"/projets/samova/leocances/AudioSet/hdfs/mel_64x500\"\n",
    "\n",
    "dataset = Audioset(root=dataset_root_path, rdcc_nbytes=256*1024**2, data_shape=(64,500), data_key=\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 901798 6745.398481973434 55326.390870915886\n"
     ]
    }
   ],
   "source": [
    "summed = dataset.targets.sum(axis=0)\n",
    "mini = summed.min()\n",
    "maxi = summed.max()\n",
    "mean = summed.mean()\n",
    "std = summed.std()\n",
    "\n",
    "print(mini, maxi, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"audioset\", type=str)\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"wideresnet28_2\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=64, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=1, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.003, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--preload_dataset\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_m = parser.add_argument_group(\"Model parameters\")\n",
    "group_m.add_argument(\"--num_classes\", default=10, type=int)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "args.checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_config': '',\n",
       " 'dataset_root': '../datasets',\n",
       " 'dataset': 'audioset',\n",
       " 'model': 'wideresnet28_2',\n",
       " 'supervised_ratio': 1.0,\n",
       " 'batch_size': 64,\n",
       " 'nb_epoch': 1,\n",
       " 'learning_rate': 0.003,\n",
       " 'resume': False,\n",
       " 'preload_dataset': False,\n",
       " 'seed': 1234,\n",
       " 'num_classes': 10,\n",
       " 'train_folds': [1, 2, 3, 4],\n",
       " 'val_folds': [5],\n",
       " 'checkpoint_root': '../model_save/',\n",
       " 'tensorboard_root': '../tensorboard/',\n",
       " 'checkpoint_path': '../model_save/audioset/supervised',\n",
       " 'tensorboard_path': '../tensorboard/audioset/supervised',\n",
       " 'tensorboard_sufix': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    parameters=vars(args),\n",
    "    seed = args.seed,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# from SSL.trainers.esc import SupervisedTrainer\n",
    "from SSL.trainers.trainers import Trainer\n",
    "\n",
    "class SupervisedTrainer(Trainer):\n",
    "    def __init__(self, model: str, dataset: str):\n",
    "        super().__init__(model, \"supervised\", dataset)\n",
    "\n",
    "trainer = SupervisedTrainer(args.model, args.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/PyTorch/audio/torchaudio/extension/extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "trainer.load_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset\n",
      "______\n",
      "eva\n",
      "['eval.h5']\n",
      "______\n",
      "unb\n",
      "['unbalanced_train_part08.h5', 'unbalanced_train_part02.h5', 'unbalanced_train_part05.h5', 'unbalanced_train_part10.h5', 'unbalanced_train_part01.h5', 'unbalanced_train_part03.h5', 'unbalanced_train_part07.h5', 'unbalanced_train_part06.h5', 'unbalanced_train_part09.h5', 'unbalanced_train_part04.h5']\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    \n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer.load_dataset(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 500]             864\n",
      "       BatchNorm2d-2          [-1, 32, 64, 500]              64\n",
      "              ReLU-3          [-1, 32, 64, 500]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 250]               0\n",
      "            Conv2d-5          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 250]              64\n",
      "              ReLU-7          [-1, 32, 32, 250]               0\n",
      "            Conv2d-8          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 250]              64\n",
      "             ReLU-10          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 250]               0\n",
      "           Conv2d-12          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 250]              64\n",
      "             ReLU-14          [-1, 32, 32, 250]               0\n",
      "           Conv2d-15          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 250]              64\n",
      "             ReLU-17          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 250]               0\n",
      "           Conv2d-19          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 250]              64\n",
      "             ReLU-21          [-1, 32, 32, 250]               0\n",
      "           Conv2d-22          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 250]              64\n",
      "             ReLU-24          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 250]               0\n",
      "           Conv2d-26          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 250]              64\n",
      "             ReLU-28          [-1, 32, 32, 250]               0\n",
      "           Conv2d-29          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 250]              64\n",
      "             ReLU-31          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 250]               0\n",
      "           Conv2d-33          [-1, 64, 16, 125]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 125]             128\n",
      "             ReLU-35          [-1, 64, 16, 125]               0\n",
      "           Conv2d-36          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 125]             128\n",
      "           Conv2d-38          [-1, 64, 16, 125]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 125]             128\n",
      "             ReLU-40          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 125]               0\n",
      "           Conv2d-42          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 125]             128\n",
      "             ReLU-44          [-1, 64, 16, 125]               0\n",
      "           Conv2d-45          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 125]             128\n",
      "             ReLU-47          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 125]               0\n",
      "           Conv2d-49          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 125]             128\n",
      "             ReLU-51          [-1, 64, 16, 125]               0\n",
      "           Conv2d-52          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 125]             128\n",
      "             ReLU-54          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 125]               0\n",
      "           Conv2d-56          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 125]             128\n",
      "             ReLU-58          [-1, 64, 16, 125]               0\n",
      "           Conv2d-59          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 125]             128\n",
      "             ReLU-61          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 125]               0\n",
      "           Conv2d-63           [-1, 128, 8, 63]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 63]             256\n",
      "             ReLU-65           [-1, 128, 8, 63]               0\n",
      "           Conv2d-66           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 63]             256\n",
      "           Conv2d-68           [-1, 128, 8, 63]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 63]             256\n",
      "             ReLU-70           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 63]               0\n",
      "           Conv2d-72           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 63]             256\n",
      "             ReLU-74           [-1, 128, 8, 63]               0\n",
      "           Conv2d-75           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 63]             256\n",
      "             ReLU-77           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 63]               0\n",
      "           Conv2d-79           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 63]             256\n",
      "             ReLU-81           [-1, 128, 8, 63]               0\n",
      "           Conv2d-82           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 63]             256\n",
      "             ReLU-84           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 63]               0\n",
      "           Conv2d-86           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 63]             256\n",
      "             ReLU-88           [-1, 128, 8, 63]               0\n",
      "           Conv2d-89           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 63]             256\n",
      "             ReLU-91           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 63]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                  [-1, 527]          67,983\n",
      "================================================================\n",
      "Total params: 1,539,247\n",
      "Trainable params: 1,539,247\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 124.15\n",
      "Params size (MB): 5.87\n",
      "Estimated Total Size (MB): 130.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "def init_loss(self):\n",
    "    self.loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "trainer.init_loss = MethodType(init_loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize optimizer\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    learning_rate=args.learning_rate,\n",
    ")\n",
    "trainer.init_optimizer(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize callbacks\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    optimizer=trainer.optimizer,\n",
    ")\n",
    "trainer.init_callbacks(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the log system\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_logs(parameters)\n",
    "\n",
    "# Save all the parameters\n",
    "tensorboard_params = {}\n",
    "for key, value in args.__dict__.items():\n",
    "    tensorboard_params[key] = str(value)\n",
    "trainer.tensorboard.add_hparams(tensorboard_params, {})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the checkpoint system\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_checkpoint(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def init_metrics(self):\n",
    "    self.metrics = DotDict(\n",
    "        fscore_fn=FScore(),\n",
    "        acc_fn=CategoricalAccuracy(),\n",
    "        avg_fn=ContinueAverage(),\n",
    "    )\n",
    "    self.maximum_tracker = track_maximum()\n",
    "\n",
    "trainer.init_metrics = MethodType(init_metrics, trainer)\n",
    "trainer.init_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_printing_form(self):\n",
    "    UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "    RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "    header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} - {:<9.9} {:<12.12}| {:<9.9}- {:<6.6}\"\n",
    "    value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} - {:<9.9} {:<10.4f}| {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "    self.header = header_form.format(\n",
    "        \".               \", \"Epoch\", \"%\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1 \",\"Time\"\n",
    "    )\n",
    "\n",
    "    self.train_form = value_form\n",
    "    self.val_form = UNDERLINE_SEQ + value_form + RESET_SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def train_fn(self, epoch: int):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.train_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(self.train_loader):\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        logits = self.model(X)\n",
    "        loss = self.loss_ce(logits, y)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=self.num_classes)\n",
    "\n",
    "            acc = M.acc_fn(pred_arg, y).mean\n",
    "            fscore = M.fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"train/Lce\", avg_ce, epoch)\n",
    "    T(\"train/f1\", fscore, epoch)\n",
    "    T(\"train/acc\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val_fn(self, epoch: int):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.val_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            # metrics\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=self.num_classes)\n",
    "\n",
    "            acc = M.acc_fn(pred_arg, y).mean\n",
    "            fscore = M.fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"val/Lce\", avg_ce, epoch)\n",
    "    T(\"val/f1\", fscore, epoch)\n",
    "    T(\"val/acc\", acc, epoch)\n",
    "\n",
    "    T(\"hyperparameters/learning_rate\", self._get_lr(), epoch)\n",
    "\n",
    "    T(\"max/acc\", self.maximum_tracker(\"acc\", acc), epoch)\n",
    "    T(\"max/f1\", self.maximum_tracker(\"f1\", fscore), epoch)\n",
    "\n",
    "    self.checkpoint.step(acc)\n",
    "    for c in self.callbacks:\n",
    "        c.step()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(self):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    # Load best epoch\n",
    "    self.checkpoint.load_best()\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.test_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            # metrics\n",
    "            pred = torch.softmax(logits, dim=1)\n",
    "            pred_arg = torch.argmax(logits, dim=1)\n",
    "            y_one_hot = F.one_hot(y, num_classes=self.num_classes)\n",
    "\n",
    "            acc = M.acc_fn(pred_arg, y).mean\n",
    "            fscore = M.fscore_fn(pred, y_one_hot).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Testing: \",\n",
    "                1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)\n",
    "trainer.train_fn = MethodType(train_fn, trainer)\n",
    "trainer.val_fn = MethodType(val_fn, trainer)\n",
    "trainer.test_fn = MethodType(test_fn, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".        Epoch  - %      - Losses:  ce     - metrics:  acc         | F1       - Time  \n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.ShortTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-596e45577f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-de15b5c19746>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semi-supervised/SSL/models/audioset.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep-Co-Training/DCT/models/wideresnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 415\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    416\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.ShortTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# Fit function\n",
    "trainer.set_printing_form()\n",
    "print(trainer.header)\n",
    "\n",
    "start_epoch = trainer.checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    trainer.train_fn(e)\n",
    "    trainer.val_fn(e)\n",
    "    \n",
    "    trainer.tensorboard.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset.lower() == \"speechcommand\":\n",
    "    trainer.test_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"377.005398pt\" version=\"1.1\" viewBox=\"0 0 1711.303125 377.005398\" width=\"1711.303125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 377.005398 \n",
       "L 1711.303125 377.005398 \n",
       "L 1711.303125 -0 \n",
       "L 0 -0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 353.127273 \n",
       "L 522.456066 353.127273 \n",
       "L 522.456066 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"me2b25cc776\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.482804\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(49.301554 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"142.90575\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(136.54325 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.328696\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(226.966196 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"323.751642\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(317.389142 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"414.174588\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(407.812088 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"504.597534\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(495.053784 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m75768ee133\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m75768ee133\" y=\"284.468047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.2 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(7.2 288.267265)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m75768ee133\" y=\"208.336437\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 212.135656)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m75768ee133\" y=\"132.204827\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 136.004046)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m75768ee133\" y=\"56.073218\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 59.872437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path clip-path=\"url(#pc5d85fdaba)\" d=\"M 52.482804 337.403306 \n",
       "L 57.003951 319.55996 \n",
       "L 61.525099 302.906172 \n",
       "L 66.046246 273.762037 \n",
       "L 70.567393 236.291015 \n",
       "L 75.088541 187.519198 \n",
       "L 79.609688 170.865401 \n",
       "L 84.130835 136.963039 \n",
       "L 88.651983 129.825696 \n",
       "L 93.17313 131.015257 \n",
       "L 97.694277 141.126491 \n",
       "L 102.215424 148.858626 \n",
       "L 106.736572 156.590738 \n",
       "L 111.257719 157.185507 \n",
       "L 115.778866 147.074273 \n",
       "L 120.300014 131.610049 \n",
       "L 124.821161 111.387581 \n",
       "L 129.342308 107.818921 \n",
       "L 133.863456 97.707687 \n",
       "L 138.384603 104.250261 \n",
       "L 142.90575 103.655492 \n",
       "L 147.426897 90.570344 \n",
       "L 151.948045 73.321767 \n",
       "L 156.469192 72.132229 \n",
       "L 160.990339 63.210556 \n",
       "L 165.511487 66.184447 \n",
       "L 170.032634 77.485219 \n",
       "L 174.553781 84.622562 \n",
       "L 179.074929 76.89045 \n",
       "L 183.596076 78.674803 \n",
       "L 188.117223 79.269572 \n",
       "L 192.638371 72.727021 \n",
       "L 197.159518 75.10612 \n",
       "L 201.680665 75.700912 \n",
       "L 206.201812 70.347899 \n",
       "L 210.72296 64.400094 \n",
       "L 215.244107 53.694114 \n",
       "L 219.765254 47.15154 \n",
       "L 224.286402 49.530639 \n",
       "L 228.807549 61.426226 \n",
       "L 233.328696 63.805325 \n",
       "L 237.849844 79.269549 \n",
       "L 242.370991 80.459133 \n",
       "L 246.892138 84.027793 \n",
       "L 251.413285 65.589678 \n",
       "L 255.934433 68.563569 \n",
       "L 260.45558 54.288883 \n",
       "L 264.976727 45.36721 \n",
       "L 269.497875 37.040306 \n",
       "L 274.019022 35.255999 \n",
       "L 278.540169 35.850768 \n",
       "L 283.061317 39.419428 \n",
       "L 287.582464 43.58288 \n",
       "L 292.103611 39.419428 \n",
       "L 296.624758 43.58288 \n",
       "L 301.145906 33.471624 \n",
       "L 305.667053 35.255976 \n",
       "L 310.1882 39.419428 \n",
       "L 314.709348 41.79855 \n",
       "L 319.230495 42.393319 \n",
       "L 323.751642 45.961979 \n",
       "L 328.27279 41.203758 \n",
       "L 332.793937 35.255954 \n",
       "L 337.315084 40.608966 \n",
       "L 341.836231 38.229867 \n",
       "L 346.357379 37.635075 \n",
       "L 350.878526 40.014197 \n",
       "L 355.399673 40.608966 \n",
       "L 359.920821 34.066415 \n",
       "L 364.441968 36.44556 \n",
       "L 368.963115 36.445537 \n",
       "L 373.484263 29.902963 \n",
       "L 378.00541 26.929072 \n",
       "L 382.526557 26.334303 \n",
       "L 387.047704 23.955181 \n",
       "L 391.568852 25.144742 \n",
       "L 396.089999 29.308194 \n",
       "L 400.611146 33.471646 \n",
       "L 405.132294 37.635098 \n",
       "L 409.653441 41.79855 \n",
       "L 414.174588 40.01422 \n",
       "L 418.695736 40.01422 \n",
       "L 423.216883 38.824659 \n",
       "L 427.73803 35.850768 \n",
       "L 432.259178 32.282108 \n",
       "L 436.780325 34.066415 \n",
       "L 441.301472 31.092547 \n",
       "L 445.822619 29.308217 \n",
       "L 450.343767 25.739511 \n",
       "L 454.864914 27.523887 \n",
       "L 459.386061 26.929095 \n",
       "L 463.907209 26.334281 \n",
       "L 468.428356 29.308194 \n",
       "L 472.949503 34.066415 \n",
       "L 477.470651 30.497755 \n",
       "L 481.991798 32.282085 \n",
       "L 486.512945 34.066415 \n",
       "L 491.034092 34.066438 \n",
       "L 495.55524 98.302456 \n",
       "L 500.076387 166.10718 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path clip-path=\"url(#pc5d85fdaba)\" d=\"M 52.482804 337.375205 \n",
       "L 57.003951 319.431325 \n",
       "L 61.525099 303.230698 \n",
       "L 66.046246 274.879605 \n",
       "L 70.567393 236.626381 \n",
       "L 75.088541 186.613816 \n",
       "L 79.609688 171.690112 \n",
       "L 84.130835 140.259681 \n",
       "L 88.651983 136.483326 \n",
       "L 93.17313 138.585189 \n",
       "L 97.694277 151.285486 \n",
       "L 102.215424 159.70428 \n",
       "L 106.736572 164.971801 \n",
       "L 111.257719 161.350706 \n",
       "L 115.778866 151.902376 \n",
       "L 120.300014 138.411663 \n",
       "L 124.821161 118.876399 \n",
       "L 129.342308 115.010332 \n",
       "L 133.863456 106.217124 \n",
       "L 138.384603 112.047559 \n",
       "L 142.90575 109.435807 \n",
       "L 147.426897 93.635037 \n",
       "L 151.948045 75.271659 \n",
       "L 156.469192 72.151674 \n",
       "L 160.990339 62.085273 \n",
       "L 165.511487 66.569094 \n",
       "L 170.032634 78.075337 \n",
       "L 174.553781 84.180853 \n",
       "L 179.074929 76.134975 \n",
       "L 183.596076 77.676329 \n",
       "L 188.117223 75.791418 \n",
       "L 192.638371 67.988176 \n",
       "L 197.159518 75.18172 \n",
       "L 201.680665 78.046522 \n",
       "L 206.201812 73.747436 \n",
       "L 210.72296 67.839223 \n",
       "L 215.244107 57.381438 \n",
       "L 219.765254 48.354533 \n",
       "L 224.286402 49.927425 \n",
       "L 228.807549 60.646428 \n",
       "L 233.328696 63.154809 \n",
       "L 237.849844 78.456648 \n",
       "L 242.370991 79.832577 \n",
       "L 246.892138 81.856434 \n",
       "L 251.413285 64.989373 \n",
       "L 255.934433 66.260274 \n",
       "L 260.45558 52.99974 \n",
       "L 264.976727 43.28756 \n",
       "L 269.497875 36.029648 \n",
       "L 274.019022 34.440897 \n",
       "L 278.540169 36.285535 \n",
       "L 283.061317 39.52171 \n",
       "L 287.582464 43.94275 \n",
       "L 292.103611 39.531081 \n",
       "L 296.624758 43.357306 \n",
       "L 301.145906 34.451334 \n",
       "L 305.667053 36.953181 \n",
       "L 310.1882 41.467881 \n",
       "L 314.709348 43.728838 \n",
       "L 319.230495 44.477121 \n",
       "L 323.751642 45.828387 \n",
       "L 328.27279 40.162311 \n",
       "L 332.793937 33.687237 \n",
       "L 337.315084 39.281139 \n",
       "L 341.836231 36.505028 \n",
       "L 346.357379 36.408781 \n",
       "L 350.878526 38.449542 \n",
       "L 355.399673 40.091975 \n",
       "L 359.920821 34.880247 \n",
       "L 364.441968 37.312552 \n",
       "L 368.963115 38.222198 \n",
       "L 373.484263 33.854909 \n",
       "L 378.00541 30.698598 \n",
       "L 382.526557 28.973963 \n",
       "L 387.047704 26.860711 \n",
       "L 391.568852 26.860711 \n",
       "L 396.089999 29.187262 \n",
       "L 400.611146 32.737068 \n",
       "L 405.132294 36.891081 \n",
       "L 409.653441 40.390562 \n",
       "L 414.174588 39.12885 \n",
       "L 418.695736 39.394697 \n",
       "L 423.216883 37.619783 \n",
       "L 427.73803 33.252493 \n",
       "L 432.259178 30.357197 \n",
       "L 436.780325 31.879946 \n",
       "L 441.301472 27.431112 \n",
       "L 445.822619 25.65622 \n",
       "L 450.343767 22.923967 \n",
       "L 454.864914 23.96285 \n",
       "L 459.386061 23.96285 \n",
       "L 463.907209 23.96285 \n",
       "L 468.428356 26.776602 \n",
       "L 472.949503 32.101277 \n",
       "L 477.470651 29.287547 \n",
       "L 481.991798 30.326385 \n",
       "L 486.512945 32.182821 \n",
       "L 491.034092 32.918852 \n",
       "L 495.55524 97.079361 \n",
       "L 500.076387 164.789653 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 353.127273 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 522.456066 353.127273 \n",
       "L 522.456066 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 353.127273 \n",
       "L 522.456066 353.127273 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 522.456066 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 37.103125 44.55625 \n",
       "L 223.25625 44.55625 \n",
       "Q 225.25625 44.55625 225.25625 42.55625 \n",
       "L 225.25625 14.2 \n",
       "Q 225.25625 12.2 223.25625 12.2 \n",
       "L 37.103125 12.2 \n",
       "Q 35.103125 12.2 35.103125 14.2 \n",
       "L 35.103125 42.55625 \n",
       "Q 35.103125 44.55625 37.103125 44.55625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_13\">\n",
       "     <path d=\"M 39.103125 20.298437 \n",
       "L 59.103125 20.298437 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_14\"/>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- val/acc = 0.9140625 -->\n",
       "     <defs>\n",
       "      <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 25.390625 72.90625 \n",
       "L 33.6875 72.90625 \n",
       "L 8.296875 -9.28125 \n",
       "L 0 -9.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-47\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 10.59375 45.40625 \n",
       "L 73.1875 45.40625 \n",
       "L 73.1875 37.203125 \n",
       "L 10.59375 37.203125 \n",
       "z\n",
       "M 10.59375 25.484375 \n",
       "L 73.1875 25.484375 \n",
       "L 73.1875 17.1875 \n",
       "L 10.59375 17.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-61\"/>\n",
       "      <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "      <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 23.798437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-47\"/>\n",
       "      <use x=\"181.933594\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"243.212891\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"298.193359\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"353.173828\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"384.960938\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"468.75\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"500.537109\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"564.160156\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"595.947266\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      <use x=\"659.570312\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      <use x=\"723.193359\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"786.816406\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"850.439453\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use x=\"914.0625\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use x=\"977.685547\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 39.103125 34.976562 \n",
       "L 59.103125 34.976562 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\"/>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- val/f1 = 0.9126984477043152 -->\n",
       "     <defs>\n",
       "      <path d=\"M 37.109375 75.984375 \n",
       "L 37.109375 68.5 \n",
       "L 28.515625 68.5 \n",
       "Q 23.6875 68.5 21.796875 66.546875 \n",
       "Q 19.921875 64.59375 19.921875 59.515625 \n",
       "L 19.921875 54.6875 \n",
       "L 34.71875 54.6875 \n",
       "L 34.71875 47.703125 \n",
       "L 19.921875 47.703125 \n",
       "L 19.921875 0 \n",
       "L 10.890625 0 \n",
       "L 10.890625 47.703125 \n",
       "L 2.296875 47.703125 \n",
       "L 2.296875 54.6875 \n",
       "L 10.890625 54.6875 \n",
       "L 10.890625 58.5 \n",
       "Q 10.890625 67.625 15.140625 71.796875 \n",
       "Q 19.390625 75.984375 28.609375 75.984375 \n",
       "z\n",
       "\" id=\"DejaVuSans-102\"/>\n",
       "      <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(67.103125 38.476562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-47\"/>\n",
       "      <use x=\"181.933594\" xlink:href=\"#DejaVuSans-102\"/>\n",
       "      <use x=\"217.138672\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      <use x=\"280.761719\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"312.548828\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"396.337891\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"428.125\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"491.748047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"523.535156\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      <use x=\"587.158203\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      <use x=\"650.78125\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use x=\"714.404297\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use x=\"778.027344\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      <use x=\"841.650391\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      <use x=\"905.273438\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"968.896484\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"1032.519531\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      <use x=\"1096.142578\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      <use x=\"1159.765625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1223.388672\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"1287.011719\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      <use x=\"1350.634766\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      <use x=\"1414.257812\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use x=\"1477.880859\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 620.926654 353.127273 \n",
       "L 1113.279596 353.127273 \n",
       "L 1113.279596 7.2 \n",
       "L 620.926654 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"643.306334\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(640.125084 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"733.72928\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(727.36678 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"824.152226\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(817.789726 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"914.575172\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(908.212672 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1004.998118\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(998.635618 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1095.421064\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(1085.877314 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"337.713889\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.0000 -->\n",
       "      <g transform=\"translate(578.936029 341.513108)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"285.248902\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 0.0005 -->\n",
       "      <g transform=\"translate(578.936029 289.048121)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"232.783915\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 0.0010 -->\n",
       "      <g transform=\"translate(578.936029 236.583134)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_26\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"180.318928\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 0.0015 -->\n",
       "      <g transform=\"translate(578.936029 184.118147)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"127.853941\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 0.0020 -->\n",
       "      <g transform=\"translate(578.936029 131.65316)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"75.388954\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0.0025 -->\n",
       "      <g transform=\"translate(578.936029 79.188173)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"620.926654\" xlink:href=\"#m75768ee133\" y=\"22.923967\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 0.0030 -->\n",
       "      <g transform=\"translate(578.936029 26.723186)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path clip-path=\"url(#p31e05b731a)\" d=\"M 643.306334 23.001632 \n",
       "L 647.827481 22.923967 \n",
       "L 652.348628 23.001632 \n",
       "L 656.869775 23.23455 \n",
       "L 661.390923 23.622491 \n",
       "L 665.91207 24.165073 \n",
       "L 670.433217 24.86176 \n",
       "L 674.954365 25.711864 \n",
       "L 679.475512 26.714547 \n",
       "L 683.996659 27.868819 \n",
       "L 688.517807 29.173541 \n",
       "L 693.038954 30.627425 \n",
       "L 697.560101 32.229036 \n",
       "L 702.081248 33.976794 \n",
       "L 706.602396 35.868974 \n",
       "L 711.123543 37.903709 \n",
       "L 715.64469 40.078991 \n",
       "L 720.165838 42.392672 \n",
       "L 724.686985 44.84247 \n",
       "L 729.208132 47.425967 \n",
       "L 733.72928 50.140613 \n",
       "L 738.250427 52.98373 \n",
       "L 742.771574 55.952511 \n",
       "L 747.292721 59.044026 \n",
       "L 751.813869 62.255225 \n",
       "L 756.335016 65.582939 \n",
       "L 760.856163 69.023884 \n",
       "L 765.377311 72.574663 \n",
       "L 769.898458 76.231773 \n",
       "L 774.419605 79.991604 \n",
       "L 778.940753 83.850446 \n",
       "L 783.4619 87.804491 \n",
       "L 787.983047 91.849837 \n",
       "L 792.504195 95.98249 \n",
       "L 797.025342 100.198374 \n",
       "L 801.546489 104.493327 \n",
       "L 806.067636 108.863111 \n",
       "L 810.588784 113.303413 \n",
       "L 815.109931 117.809851 \n",
       "L 819.631078 122.377978 \n",
       "L 824.152226 127.003286 \n",
       "L 828.673373 131.68121 \n",
       "L 833.19452 136.407134 \n",
       "L 837.715668 141.176393 \n",
       "L 842.236815 145.984281 \n",
       "L 846.757962 150.826053 \n",
       "L 851.279109 155.696931 \n",
       "L 855.800257 160.592108 \n",
       "L 860.321404 165.506754 \n",
       "L 864.842551 170.436016 \n",
       "L 869.363699 175.375033 \n",
       "L 873.884846 180.318928 \n",
       "L 878.405993 185.262823 \n",
       "L 882.927141 190.201839 \n",
       "L 887.448288 195.131102 \n",
       "L 891.969435 200.045747 \n",
       "L 896.490582 204.940924 \n",
       "L 901.01173 209.811803 \n",
       "L 905.532877 214.653575 \n",
       "L 910.054024 219.461463 \n",
       "L 914.575172 224.230722 \n",
       "L 919.096319 228.956646 \n",
       "L 923.617466 233.63457 \n",
       "L 928.138614 238.259877 \n",
       "L 932.659761 242.828005 \n",
       "L 937.180908 247.334443 \n",
       "L 941.702055 251.774745 \n",
       "L 946.223203 256.144529 \n",
       "L 950.74435 260.439482 \n",
       "L 955.265497 264.655365 \n",
       "L 959.786645 268.788019 \n",
       "L 964.307792 272.833365 \n",
       "L 968.828939 276.78741 \n",
       "L 973.350087 280.646252 \n",
       "L 977.871234 284.406083 \n",
       "L 982.392381 288.063193 \n",
       "L 986.913529 291.613972 \n",
       "L 991.434676 295.054916 \n",
       "L 995.955823 298.38263 \n",
       "L 1000.47697 301.59383 \n",
       "L 1004.998118 304.685345 \n",
       "L 1009.519265 307.654126 \n",
       "L 1014.040412 310.497243 \n",
       "L 1018.56156 313.211889 \n",
       "L 1023.082707 315.795386 \n",
       "L 1027.603854 318.245184 \n",
       "L 1032.125002 320.558865 \n",
       "L 1036.646149 322.734146 \n",
       "L 1041.167296 324.768881 \n",
       "L 1045.688443 326.661062 \n",
       "L 1050.209591 328.40882 \n",
       "L 1054.730738 330.010431 \n",
       "L 1059.251885 331.464315 \n",
       "L 1063.773033 332.769037 \n",
       "L 1068.29418 333.923308 \n",
       "L 1072.815327 334.925991 \n",
       "L 1077.336475 335.776096 \n",
       "L 1081.857622 336.472783 \n",
       "L 1086.378769 337.015364 \n",
       "L 1090.899916 337.403306 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 620.926654 353.127273 \n",
       "L 620.926654 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 1113.279596 353.127273 \n",
       "L 1113.279596 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 620.926654 353.127273 \n",
       "L 1113.279596 353.127273 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 620.926654 7.2 \n",
       "L 1113.279596 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_2\">\n",
       "    <g id=\"patch_13\">\n",
       "     <path d=\"M 874.392096 30.15625 \n",
       "L 1106.279596 30.15625 \n",
       "Q 1108.279596 30.15625 1108.279596 28.15625 \n",
       "L 1108.279596 14.2 \n",
       "Q 1108.279596 12.2 1106.279596 12.2 \n",
       "L 874.392096 12.2 \n",
       "Q 872.392096 12.2 872.392096 14.2 \n",
       "L 872.392096 28.15625 \n",
       "Q 872.392096 30.15625 874.392096 30.15625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_31\">\n",
       "     <path d=\"M 876.392096 20.298437 \n",
       "L 896.392096 20.298437 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_32\"/>\n",
       "    <g id=\"text_26\">\n",
       "     <!-- hyperparameters/learning_rate = 0.003 -->\n",
       "     <defs>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "      <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-121\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-103\"/>\n",
       "      <path d=\"M 50.984375 -16.609375 \n",
       "L 50.984375 -23.578125 \n",
       "L -0.984375 -23.578125 \n",
       "L -0.984375 -16.609375 \n",
       "z\n",
       "\" id=\"DejaVuSans-95\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(904.392096 23.798437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-104\"/>\n",
       "      <use x=\"63.378906\" xlink:href=\"#DejaVuSans-121\"/>\n",
       "      <use x=\"122.558594\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"186.035156\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"247.558594\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"288.671875\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"352.148438\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"413.427734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"454.541016\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"515.820312\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"613.232422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"674.755859\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"713.964844\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"775.488281\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"816.601562\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"868.701172\" xlink:href=\"#DejaVuSans-47\"/>\n",
       "      <use x=\"902.392578\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"930.175781\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"991.699219\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"1052.978516\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"1094.076172\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"1157.455078\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"1185.238281\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"1248.617188\" xlink:href=\"#DejaVuSans-103\"/>\n",
       "      <use x=\"1312.09375\" xlink:href=\"#DejaVuSans-95\"/>\n",
       "      <use x=\"1362.09375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"1403.207031\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"1464.486328\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"1503.695312\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"1565.21875\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"1597.005859\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"1680.794922\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"1712.582031\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1776.205078\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"1807.992188\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1871.615234\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1935.238281\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 1211.750184 353.127273 \n",
       "L 1704.103125 353.127273 \n",
       "L 1704.103125 7.2 \n",
       "L 1211.750184 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_5\">\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1234.129863\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(1230.948613 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_34\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1324.552809\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(1318.190309 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1414.975755\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_29\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(1408.613255 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_36\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1505.398701\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(1499.036201 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1595.821647\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(1589.459147 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_18\">\n",
       "     <g id=\"line2d_38\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1686.244593\" xlink:href=\"#me2b25cc776\" y=\"353.127273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_32\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(1676.700843 367.72571)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_6\">\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#m75768ee133\" y=\"294.088227\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(1188.847059 297.887446)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_40\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#m75768ee133\" y=\"218.1385\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(1188.847059 221.937719)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#m75768ee133\" y=\"142.188773\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(1188.847059 145.987992)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_42\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#m75768ee133\" y=\"66.239046\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(1188.847059 70.038264)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_43\">\n",
       "    <path clip-path=\"url(#p5a4b5eddaf)\" d=\"M 1234.129863 337.403306 \n",
       "L 1238.65101 328.502947 \n",
       "L 1243.172158 328.502947 \n",
       "L 1247.693305 281.034368 \n",
       "L 1252.214452 281.034368 \n",
       "L 1256.735599 192.030781 \n",
       "L 1261.256747 141.595416 \n",
       "L 1265.777894 85.226477 \n",
       "L 1270.299041 85.226477 \n",
       "L 1274.820189 85.226477 \n",
       "L 1279.341336 85.226477 \n",
       "L 1283.862483 85.226477 \n",
       "L 1288.383631 85.226477 \n",
       "L 1292.904778 85.226477 \n",
       "L 1297.425925 85.226477 \n",
       "L 1301.947072 85.226477 \n",
       "L 1306.46822 85.226477 \n",
       "L 1310.989367 58.525402 \n",
       "L 1315.510514 58.525402 \n",
       "L 1320.031662 58.525402 \n",
       "L 1324.552809 58.525402 \n",
       "L 1329.073956 58.525402 \n",
       "L 1333.595104 55.558615 \n",
       "L 1338.116251 55.558615 \n",
       "L 1342.637398 52.591829 \n",
       "L 1347.158546 52.591829 \n",
       "L 1351.679693 52.591829 \n",
       "L 1356.20084 52.591829 \n",
       "L 1360.721987 52.591829 \n",
       "L 1365.243135 52.591829 \n",
       "L 1369.764282 52.591829 \n",
       "L 1374.285429 52.591829 \n",
       "L 1378.806577 52.591829 \n",
       "L 1383.327724 52.591829 \n",
       "L 1387.848871 52.591829 \n",
       "L 1392.370019 52.591829 \n",
       "L 1396.891166 52.591829 \n",
       "L 1401.412313 43.69147 \n",
       "L 1405.93346 40.724684 \n",
       "L 1410.454608 40.724684 \n",
       "L 1414.975755 40.724684 \n",
       "L 1419.496902 40.724684 \n",
       "L 1424.01805 40.724684 \n",
       "L 1428.539197 40.724684 \n",
       "L 1433.060344 40.724684 \n",
       "L 1437.581492 40.724684 \n",
       "L 1442.102639 34.791112 \n",
       "L 1446.623786 34.791112 \n",
       "L 1451.144933 34.791112 \n",
       "L 1455.666081 28.857539 \n",
       "L 1460.187228 28.857539 \n",
       "L 1464.708375 25.890753 \n",
       "L 1469.229523 25.890753 \n",
       "L 1473.75067 25.890753 \n",
       "L 1478.271817 25.890753 \n",
       "L 1482.792965 25.890753 \n",
       "L 1487.314112 25.890753 \n",
       "L 1491.835259 22.923967 \n",
       "L 1496.356406 22.923967 \n",
       "L 1500.877554 22.923967 \n",
       "L 1505.398701 22.923967 \n",
       "L 1509.919848 22.923967 \n",
       "L 1514.440996 22.923967 \n",
       "L 1518.962143 22.923967 \n",
       "L 1523.48329 22.923967 \n",
       "L 1528.004438 22.923967 \n",
       "L 1532.525585 22.923967 \n",
       "L 1537.046732 22.923967 \n",
       "L 1541.567879 22.923967 \n",
       "L 1546.089027 22.923967 \n",
       "L 1550.610174 22.923967 \n",
       "L 1555.131321 22.923967 \n",
       "L 1559.652469 22.923967 \n",
       "L 1564.173616 22.923967 \n",
       "L 1568.694763 22.923967 \n",
       "L 1573.215911 22.923967 \n",
       "L 1577.737058 22.923967 \n",
       "L 1582.258205 22.923967 \n",
       "L 1586.779353 22.923967 \n",
       "L 1591.3005 22.923967 \n",
       "L 1595.821647 22.923967 \n",
       "L 1600.342794 22.923967 \n",
       "L 1604.863942 22.923967 \n",
       "L 1609.385089 22.923967 \n",
       "L 1613.906236 22.923967 \n",
       "L 1618.427384 22.923967 \n",
       "L 1622.948531 22.923967 \n",
       "L 1627.469678 22.923967 \n",
       "L 1631.990826 22.923967 \n",
       "L 1636.511973 22.923967 \n",
       "L 1641.03312 22.923967 \n",
       "L 1645.554267 22.923967 \n",
       "L 1650.075415 22.923967 \n",
       "L 1654.596562 22.923967 \n",
       "L 1659.117709 22.923967 \n",
       "L 1663.638857 22.923967 \n",
       "L 1668.160004 22.923967 \n",
       "L 1672.681151 22.923967 \n",
       "L 1677.202299 22.923967 \n",
       "L 1681.723446 22.923967 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 1211.750184 353.127273 \n",
       "L 1211.750184 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 1704.103125 353.127273 \n",
       "L 1704.103125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 1211.750184 353.127273 \n",
       "L 1704.103125 353.127273 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 1211.750184 7.2 \n",
       "L 1704.103125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_3\">\n",
       "    <g id=\"patch_19\">\n",
       "     <path d=\"M 1218.750184 29.878125 \n",
       "L 1361.845496 29.878125 \n",
       "Q 1363.845496 29.878125 1363.845496 27.878125 \n",
       "L 1363.845496 14.2 \n",
       "Q 1363.845496 12.2 1361.845496 12.2 \n",
       "L 1218.750184 12.2 \n",
       "Q 1216.750184 12.2 1216.750184 14.2 \n",
       "L 1216.750184 27.878125 \n",
       "Q 1216.750184 29.878125 1218.750184 29.878125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_44\">\n",
       "     <path d=\"M 1220.750184 20.298437 \n",
       "L 1240.750184 20.298437 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_45\"/>\n",
       "    <g id=\"text_37\">\n",
       "     <!-- max/acc = 0.9140625 -->\n",
       "     <defs>\n",
       "      <path d=\"M 54.890625 54.6875 \n",
       "L 35.109375 28.078125 \n",
       "L 55.90625 0 \n",
       "L 45.3125 0 \n",
       "L 29.390625 21.484375 \n",
       "L 13.484375 0 \n",
       "L 2.875 0 \n",
       "L 24.125 28.609375 \n",
       "L 4.6875 54.6875 \n",
       "L 15.28125 54.6875 \n",
       "L 29.78125 35.203125 \n",
       "L 44.28125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-120\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(1248.750184 23.798437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"158.691406\" xlink:href=\"#DejaVuSans-120\"/>\n",
       "      <use x=\"217.871094\" xlink:href=\"#DejaVuSans-47\"/>\n",
       "      <use x=\"251.5625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"312.841797\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"367.822266\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"422.802734\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"454.589844\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"538.378906\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"570.166016\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"633.789062\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"665.576172\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      <use x=\"729.199219\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      <use x=\"792.822266\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"856.445312\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"920.068359\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use x=\"983.691406\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      <use x=\"1047.314453\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc5d85fdaba\">\n",
       "   <rect height=\"345.927273\" width=\"492.352941\" x=\"30.103125\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p31e05b731a\">\n",
       "   <rect height=\"345.927273\" width=\"492.352941\" x=\"620.926654\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p5a4b5eddaf\">\n",
       "   <rect height=\"345.927273\" width=\"492.352941\" x=\"1211.750184\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 2160x1008 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "T=trainer.tensorboard.history\n",
    "\n",
    "x = list(range(trainer.checkpoint.epoch_counter))\n",
    "sm = lambda y, w: np.convolve(y, np.ones(w)/w, mode='same')\n",
    "pp = lambda k: plt.plot(x, T[k], label=f\"{k} = {max(T[k])}\")\n",
    "spp = lambda k: plt.plot(x, sm(T[k], 5), label=f\"{k} = {max(T[k])}\")\n",
    "\n",
    "\n",
    "plt.figure(0, figsize=(30, 14))\n",
    "plt.subplot(2, 3, 1)\n",
    "spp(\"val/acc\")\n",
    "spp(\"val/f1\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "pp(\"hyperparameters/learning_rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "pp(\"max/acc\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .llll||=||llll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `fit` function from trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n",
      "Load the dataset\n",
      "Dataset already downloaded and verified.\n",
      "Dataset already downloaded and verified.\n",
      "Create the model\n",
      "1872 10\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 24, 64, 431]             240\n",
      "         MaxPool2d-2          [-1, 24, 16, 215]               0\n",
      "       BatchNorm2d-3          [-1, 24, 16, 215]              48\n",
      "             ReLU6-4          [-1, 24, 16, 215]               0\n",
      "            Conv2d-5          [-1, 48, 16, 215]          10,416\n",
      "         MaxPool2d-6           [-1, 48, 4, 107]               0\n",
      "       BatchNorm2d-7           [-1, 48, 4, 107]              96\n",
      "             ReLU6-8           [-1, 48, 4, 107]               0\n",
      "            Conv2d-9           [-1, 72, 4, 107]          31,176\n",
      "        MaxPool2d-10            [-1, 72, 2, 53]               0\n",
      "      BatchNorm2d-11            [-1, 72, 2, 53]             144\n",
      "            ReLU6-12            [-1, 72, 2, 53]               0\n",
      "           Conv2d-13            [-1, 72, 2, 53]          46,728\n",
      "        MaxPool2d-14            [-1, 72, 1, 26]               0\n",
      "      BatchNorm2d-15            [-1, 72, 1, 26]             144\n",
      "            ReLU6-16            [-1, 72, 1, 26]               0\n",
      "           Conv2d-17            [-1, 72, 1, 26]          46,728\n",
      "            ReLU6-18            [-1, 72, 1, 26]               0\n",
      "          Flatten-19                 [-1, 1872]               0\n",
      "          Dropout-20                 [-1, 1872]               0\n",
      "           Linear-21                   [-1, 10]          18,730\n",
      "================================================================\n",
      "Total params: 154,450\n",
      "Trainable params: 154,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 9.24\n",
      "Params size (MB): 0.59\n",
      "Estimated Total Size (MB): 9.93\n",
      "----------------------------------------------------------------\n",
      "Initialize optimizer\n",
      "Initialize callbacks\n",
      "Prepare the log system\n",
      "Prepare the checkpoint system\n",
      ">>> Trainer is ready\n"
     ]
    }
   ],
   "source": [
    "from SSL.trainers import SupervisedTrainer\n",
    "\n",
    "training_params=dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    learning_rate=args.learning_rate,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    seed=args.seed,\n",
    "\n",
    ")\n",
    "other_params = dict(\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    training_params,\n",
    "    **other_params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 1      - 100    -          2.0345 -           0.2656    | 0.0965   - 1.8048\n",
      "\u001b[1;4mValidati 1      - 100    -          2.6831 -           0.1953    | 0.2777   - 0.4444\u001b[0m\n",
      "Training 2      - 100    -          1.2135 -           0.5469    | 0.4048   - 0.1740\n",
      "\u001b[1;4mValidati 2      - 100    -          2.9214 -           0.3047    | 0.2911   - 0.0137\u001b[0m\n",
      "Training 3      - 100    -          0.8702 -           0.6656    | 0.6131   - 0.1736\n",
      "\u001b[1;4mValidati 3      - 100    -          2.5288 -           0.2422    | 0.2589   - 0.0122\u001b[0m\n",
      "Training 4      - 100    -          0.7645 -           0.6656    | 0.6485   - 0.1747\n",
      "\u001b[1;4mValidati 4      - 100    -          1.7741 -           0.4922    | 0.5164   - 0.0137\u001b[0m\n",
      "Training 5      - 100    -          0.5648 -           0.7781    | 0.7831   - 0.1631\n",
      "\u001b[1;4mValidati 5      - 100    -          1.2882 -           0.6953    | 0.6906   - 0.0140\u001b[0m\n",
      "Training 6      - 100    -          0.4015 -           0.8469    | 0.8583   - 0.1590\n",
      "\u001b[1;4mValidati 6      - 100    -          3.0976 -           0.5625    | 0.5700   - 0.0129\u001b[0m\n",
      "Training 7      - 100    -          0.3375 -           0.8625    | 0.8601   - 0.1591\n",
      "\u001b[1;4mValidati 7      - 100    -          1.4139 -           0.6250    | 0.6270   - 0.0128\u001b[0m\n",
      "Training 8      - 100    -          0.3002 -           0.8906    | 0.8882   - 0.1610\n",
      "\u001b[1;4mValidati 8      - 100    -          1.6447 -           0.6484    | 0.6583   - 0.0127\u001b[0m\n",
      "Training 9      - 100    -          0.2320 -           0.9250    | 0.9137   - 0.1601\n",
      "\u001b[1;4mValidati 9      - 100    -          0.7055 -           0.7891    | 0.7891   - 0.0133\u001b[0m\n",
      "Training 10     - 100    -          0.2220 -           0.9406    | 0.9403   - 0.1583\n",
      "\u001b[1;4mValidati 10     - 100    -          1.2592 -           0.7656    | 0.7358   - 0.0132\u001b[0m\n",
      "Training 11     - 100    -          0.1467 -           0.9625    | 0.9638   - 0.1592\n",
      "\u001b[1;4mValidati 11     - 100    -          1.0127 -           0.7812    | 0.7611   - 0.0134\u001b[0m\n",
      "Training 12     - 100    -          0.1416 -           0.9438    | 0.9450   - 0.1594\n",
      "\n",
      "Training 13     - 100    -          0.1577 -           0.9594    | 0.9639   - 0.1611\n",
      "\u001b[1;4mValidati 13     - 100    -          1.5235 -           0.6484    | 0.6575   - 0.0148\u001b[0m\n",
      "Training 14     - 100    -          0.2252 -           0.9250    | 0.9234   - 0.1625\n",
      "\u001b[1;4mValidati 14     - 100    -          0.7317 -           0.8047    | 0.8002   - 0.0128\u001b[0m\n",
      "Training 15     - 100    -          0.2259 -           0.9250    | 0.9287   - 0.1922\n",
      "\u001b[1;4mValidati 15     - 100    -          0.6366 -           0.9141    | 0.8916   - 0.0188\u001b[0m\n",
      "Training 16     - 100    -          0.1327 -           0.9500    | 0.9465   - 0.1800\n",
      "\u001b[1;4mValidati 16     - 100    -          1.0778 -           0.8203    | 0.8344   - 0.0113\u001b[0m\n",
      "Training 17     - 100    -          0.1261 -           0.9656    | 0.9670   - 0.1749\n",
      "\u001b[1;4mValidati 17     - 100    -          1.2098 -           0.7656    | 0.7713   - 0.0130\u001b[0m\n",
      "Training 18     - 100    -          0.1285 -           0.9625    | 0.9623   - 0.1679\n",
      "\u001b[1;4mValidati 18     - 100    -          1.0875 -           0.7812    | 0.7812   - 0.0123\u001b[0m\n",
      "Training 19     - 100    -          0.1069 -           0.9750    | 0.9750   - 0.1675\n",
      "\u001b[1;4mValidati 19     - 100    -          1.0303 -           0.8281    | 0.8269   - 0.0120\u001b[0m\n",
      "Training 20     - 100    -          0.1005 -           0.9594    | 0.9624   - 0.1723\n",
      "\u001b[1;4mValidati 20     - 100    -          1.5312 -           0.7734    | 0.7644   - 0.0144\u001b[0m\n",
      "Training 21     - 100    -          0.1574 -           0.9625    | 0.9655   - 0.1655\n",
      "\u001b[1;4mValidati 21     - 100    -          1.3431 -           0.7734    | 0.7734   - 0.0134\u001b[0m\n",
      "Training 22     - 100    -          0.0545 -           0.9781    | 0.9812   - 0.1685\n",
      "\n",
      "Training 23     - 100    -          0.0567 -           0.9844    | 0.9828   - 0.1626\n",
      "\u001b[1;4mValidati 23     - 100    -          1.4051 -           0.8203    | 0.8203   - 0.0127\u001b[0m\n",
      "Training 24     - 100    -          0.0897 -           0.9719    | 0.9719   - 0.1797\n",
      "\u001b[1;4mValidati 24     - 100    -          0.6498 -           0.8984    | 0.9018   - 0.0143\u001b[0m\n",
      "Training 25     - 100    -          0.0486 -           0.9844    | 0.9843   - 0.1687\n",
      "\u001b[1;4mValidati 25     - 100    -          0.7304 -           0.8125    | 0.8036   - 0.0123\u001b[0m\n",
      "Training 26     - 100    -          0.0393 -           0.9906    | 0.9922   - 0.1635\n",
      "\u001b[1;4mValidati 26     - 100    -          1.0169 -           0.8203    | 0.8324   - 0.0117\u001b[0m\n",
      "Training 27     - 100    -          0.0281 -           0.9969    | 0.9953   - 0.1672\n",
      "\u001b[1;4mValidati 27     - 100    -          0.7993 -           0.7891    | 0.7891   - 0.0137\u001b[0m\n",
      "Training 28     - 100    -          0.0135 -           1.0000    | 0.9984   - 0.1627\n",
      "\u001b[1;4mValidati 28     - 100    -          0.6832 -           0.8672    | 0.8703   - 0.0124\u001b[0m\n",
      "Training 29     - 100    -          0.0102 -           1.0000    | 1.0000   - 0.1724\n",
      "\u001b[1;4mValidati 29     - 100    -          1.0422 -           0.8750    | 0.8750   - 0.0126\u001b[0m\n",
      "Training 30     - 100    -          0.0160 -           0.9938    | 0.9938   - 0.1718\n",
      "\u001b[1;4mValidati 30     - 100    -          1.3404 -           0.7891    | 0.8012   - 0.0148\u001b[0m\n",
      "Training 31     - 100    -          0.0220 -           0.9938    | 0.9938   - 0.1698\n",
      "\n",
      "Training 32     - 100    -          0.0251 -           0.9875    | 0.9859   - 0.1605\n",
      "\u001b[1;4mValidati 32     - 100    -          1.1158 -           0.8594    | 0.8594   - 0.0136\u001b[0m\n",
      "Training 33     - 100    -          0.0066 -           1.0000    | 1.0000   - 0.1621\n",
      "\u001b[1;4mValidati 33     - 100    -          0.6057 -           0.8984    | 0.9016   - 0.0129\u001b[0m\n",
      "Training 34     - 100    -          0.0470 -           0.9875    | 0.9875   - 0.1640\n",
      "\u001b[1;4mValidati 34     - 100    -          1.5975 -           0.7734    | 0.7734   - 0.0116\u001b[0m\n",
      "Training 35     - 100    -          0.0163 -           0.9969    | 0.9969   - 0.1665\n",
      "\u001b[1;4mValidati 35     - 100    -          0.9191 -           0.8125    | 0.8125   - 0.0132\u001b[0m\n",
      "Training 36     - 100    -          0.0250 -           0.9938    | 0.9938   - 0.1647\n",
      "\u001b[1;4mValidati 36     - 100    -          0.9065 -           0.8047    | 0.8078   - 0.0123\u001b[0m\n",
      "Training 37     - 100    -          0.0099 -           1.0000    | 1.0000   - 0.1658\n",
      "\u001b[1;4mValidati 37     - 100    -          1.0024 -           0.8203    | 0.8236   - 0.0123\u001b[0m\n",
      "Training 38     - 100    -          0.0054 -           1.0000    | 1.0000   - 0.1684\n",
      "\u001b[1;4mValidati 38     - 100    -          0.9261 -           0.8516    | 0.8548   - 0.0126\u001b[0m\n",
      "Training 39     - 100    -          0.0037 -           1.0000    | 1.0000   - 0.1698\n",
      "\n",
      "Training 40     - 100    -          0.0029 -           1.0000    | 1.0000   - 0.1657\n",
      "\u001b[1;4mValidati 40     - 100    -          0.7354 -           0.8750    | 0.8782   - 0.0117\u001b[0m\n",
      "Training 41     - 100    -          0.0080 -           1.0000    | 1.0000   - 0.1716\n",
      "\u001b[1;4mValidati 41     - 100    -          1.3444 -           0.8047    | 0.8002   - 0.0114\u001b[0m\n",
      "Training 42     - 100    -          0.0023 -           1.0000    | 1.0000   - 0.1695\n",
      "\u001b[1;4mValidati 42     - 100    -          0.8021 -           0.8438    | 0.8391   - 0.0138\u001b[0m\n",
      "Training 43     - 100    -          0.0042 -           1.0000    | 1.0000   - 0.1843\n",
      "\u001b[1;4mValidati 43     - 100    -          1.4877 -           0.7812    | 0.7812   - 0.0160\u001b[0m\n",
      "Training 44     - 100    -          0.0021 -           1.0000    | 1.0000   - 0.1794\n",
      "\u001b[1;4mValidati 44     - 100    -          0.8956 -           0.8594    | 0.8594   - 0.0112\u001b[0m\n",
      "Training 45     - 100    -          0.0072 -           1.0000    | 1.0000   - 0.1503\n",
      "\u001b[1;4mValidati 45     - 100    -          0.8697 -           0.8594    | 0.8594   - 0.0118\u001b[0m\n",
      "Training 46     - 100    -          0.0032 -           1.0000    | 1.0000   - 0.1700\n",
      "\u001b[1;4mValidati 46     - 100    -          1.0209 -           0.8359    | 0.8359   - 0.0135\u001b[0m\n",
      "Training 47     - 100    -          0.0014 -           1.0000    | 1.0000   - 0.1652\n",
      "\u001b[1;4mValidati 47     - 100    -          0.6443 -           0.9141    | 0.9141   - 0.0117\u001b[0m\n",
      "Training 48     - 100    -          0.0016 -           1.0000    | 1.0000   - 0.1492\n",
      "\u001b[1;4mValidati 48     - 100    -          1.1430 -           0.8672    | 0.8672   - 0.0113\u001b[0m\n",
      "Training 49     - 100    -          0.0028 -           1.0000    | 1.0000   - 0.1501\n",
      "\u001b[1;4mValidati 49     - 100    -          1.0584 -           0.8672    | 0.8672   - 0.0121\u001b[0m\n",
      "Training 50     - 100    -          0.0015 -           1.0000    | 1.0000   - 0.1673\n",
      "\u001b[1;4mValidati 50     - 100    -          1.3093 -           0.8438    | 0.8438   - 0.0136\u001b[0m\n",
      "Training 51     - 100    -          0.0020 -           1.0000    | 1.0000   - 0.1628\n",
      "\u001b[1;4mValidati 51     - 100    -          0.9584 -           0.8672    | 0.8672   - 0.0127\u001b[0m\n",
      "Training 52     - 100    -          0.0032 -           1.0000    | 1.0000   - 0.1546\n",
      "\u001b[1;4mValidati 52     - 100    -          0.9169 -           0.8672    | 0.8672   - 0.0141\u001b[0m\n",
      "Training 53     - 100    -          0.0018 -           1.0000    | 1.0000   - 0.1567\n",
      "\u001b[1;4mValidati 53     - 100    -          0.9487 -           0.8594    | 0.8594   - 0.0137\u001b[0m\n",
      "Training 54     - 100    -          0.0017 -           1.0000    | 1.0000   - 0.1573\n",
      "\n",
      "Training 55     - 100    -          0.0026 -           1.0000    | 1.0000   - 0.1541\n",
      "\u001b[1;4mValidati 55     - 100    -          0.9252 -           0.8516    | 0.8516   - 0.0113\u001b[0m\n",
      "Training 56     - 100    -          0.0283 -           0.9969    | 0.9969   - 0.1515\n",
      "\u001b[1;4mValidati 56     - 100    -          1.0983 -           0.8359    | 0.8359   - 0.0119\u001b[0m\n",
      "Training 57     - 100    -          0.0212 -           0.9938    | 0.9938   - 0.1559\n",
      "\u001b[1;4mValidati 57     - 100    -          0.7282 -           0.8906    | 0.8937   - 0.0126\u001b[0m\n",
      "Training 58     - 100    -          0.0013 -           1.0000    | 1.0000   - 0.1526\n",
      "\u001b[1;4mValidati 58     - 100    -          1.6725 -           0.7578    | 0.7578   - 0.0123\u001b[0m\n",
      "Training 59     - 100    -          0.0032 -           1.0000    | 1.0000   - 0.1534\n",
      "\u001b[1;4mValidati 59     - 100    -          1.0377 -           0.8750    | 0.8750   - 0.0158\u001b[0m\n",
      "Training 60     - 100    -          0.0050 -           0.9969    | 0.9984   - 0.1690\n",
      "\u001b[1;4mValidati 60     - 100    -          0.7494 -           0.8906    | 0.8968   - 0.0172\u001b[0m\n",
      "Training 61     - 100    -          0.0049 -           1.0000    | 1.0000   - 0.1772\n",
      "\u001b[1;4mValidati 61     - 100    -          0.9321 -           0.8438    | 0.8469   - 0.0130\u001b[0m\n",
      "Training 62     - 100    -          0.0016 -           1.0000    | 1.0000   - 0.1568\n",
      "\n",
      "Training 63     - 100    -          0.0047 -           1.0000    | 1.0000   - 0.1591\n",
      "\u001b[1;4mValidati 63     - 100    -          0.8593 -           0.8438    | 0.8438   - 0.0114\u001b[0m\n",
      "Training 64     - 100    -          0.0024 -           1.0000    | 1.0000   - 0.1575\n",
      "\u001b[1;4mValidati 64     - 100    -          1.0342 -           0.8516    | 0.8548   - 0.0112\u001b[0m\n",
      "Training 65     - 100    -          0.0016 -           1.0000    | 1.0000   - 0.1573\n",
      "\u001b[1;4mValidati 65     - 100    -          1.1626 -           0.8594    | 0.8412   - 0.0130\u001b[0m\n",
      "Training 66     - 100    -          0.0024 -           1.0000    | 1.0000   - 0.1575\n",
      "\u001b[1;4mValidati 66     - 100    -          0.7085 -           0.8750    | 0.8703   - 0.0127\u001b[0m\n",
      "Training 67     - 100    -          0.0028 -           1.0000    | 1.0000   - 0.1583\n",
      "\u001b[1;4mValidati 67     - 100    -          1.4357 -           0.7812    | 0.7803   - 0.0127\u001b[0m\n",
      "Training 68     - 100    -          0.0010 -           1.0000    | 1.0000   - 0.1588\n",
      "\u001b[1;4mValidati 68     - 100    -          1.1661 -           0.8359    | 0.8423   - 0.0131\u001b[0m\n",
      "Training 69     - 100    -          0.0019 -           1.0000    | 1.0000   - 0.1679\n",
      "\u001b[1;4mValidati 69     - 100    -          0.9614 -           0.8125    | 0.8110   - 0.0150\u001b[0m\n",
      "Training 70     - 100    -          0.0021 -           1.0000    | 1.0000   - 0.1651\n",
      "\n",
      "Training 71     - 100    -          0.0012 -           1.0000    | 1.0000   - 0.1576\n",
      "\u001b[1;4mValidati 71     - 100    -          0.8392 -           0.8359    | 0.8343   - 0.0116\u001b[0m\n",
      "Training 72     - 100    -          0.0008 -           1.0000    | 1.0000   - 0.1563\n",
      "\u001b[1;4mValidati 72     - 100    -          0.8002 -           0.8203    | 0.8110   - 0.0126\u001b[0m\n",
      "Training 73     - 100    -          0.0014 -           1.0000    | 1.0000   - 0.1586\n",
      "\u001b[1;4mValidati 73     - 100    -          0.9091 -           0.8672    | 0.8576   - 0.0122\u001b[0m\n",
      "Training 74     - 100    -          0.0017 -           1.0000    | 1.0000   - 0.1584\n",
      "\u001b[1;4mValidati 74     - 100    -          1.1206 -           0.8516    | 0.8288   - 0.0116\u001b[0m\n",
      "Training 75     - 100    -          0.0031 -           1.0000    | 1.0000   - 0.1596\n",
      "\u001b[1;4mValidati 75     - 100    -          0.9651 -           0.8438    | 0.8579   - 0.0118\u001b[0m\n",
      "Training 76     - 100    -          0.0011 -           1.0000    | 1.0000   - 0.1583\n",
      "\u001b[1;4mValidati 76     - 100    -          1.4329 -           0.8047    | 0.8081   - 0.0127\u001b[0m\n",
      "Training 77     - 100    -          0.0023 -           1.0000    | 1.0000   - 0.1584\n",
      "\n",
      "Training 78     - 100    -          0.0019 -           1.0000    | 1.0000   - 0.1590\n",
      "\u001b[1;4mValidati 78     - 100    -          0.7884 -           0.8594    | 0.8548   - 0.0127\u001b[0m\n",
      "Training 79     - 100    -          0.0008 -           1.0000    | 1.0000   - 0.1620\n",
      "\u001b[1;4mValidati 79     - 100    -          0.7015 -           0.9062    | 0.9016   - 0.0130\u001b[0m\n",
      "Training 80     - 100    -          0.0010 -           1.0000    | 1.0000   - 0.1597\n",
      "\u001b[1;4mValidati 80     - 100    -          1.5795 -           0.8359    | 0.8314   - 0.0129\u001b[0m\n",
      "Training 81     - 100    -          0.0017 -           1.0000    | 1.0000   - 0.1588\n",
      "\u001b[1;4mValidati 81     - 100    -          0.9430 -           0.8594    | 0.8548   - 0.0131\u001b[0m\n",
      "Training 82     - 100    -          0.0011 -           1.0000    | 1.0000   - 0.1590\n",
      "\u001b[1;4mValidati 82     - 100    -          0.7596 -           0.8750    | 0.8579   - 0.0123\u001b[0m\n",
      "Training 83     - 100    -          0.0022 -           1.0000    | 1.0000   - 0.1569\n",
      "\u001b[1;4mValidati 83     - 100    -          1.2627 -           0.8359    | 0.8359   - 0.0125\u001b[0m\n",
      "Training 84     - 100    -          0.0007 -           1.0000    | 1.0000   - 0.1576\n",
      "\n",
      "Training 85     - 100    -          0.0009 -           1.0000    | 1.0000   - 0.1594\n",
      "\u001b[1;4mValidati 85     - 100    -          1.2731 -           0.8516    | 0.8516   - 0.0119\u001b[0m\n",
      "Training 86     - 100    -          0.0009 -           1.0000    | 1.0000   - 0.1587\n",
      "\u001b[1;4mValidati 86     - 100    -          0.7867 -           0.8750    | 0.8703   - 0.0120\u001b[0m\n",
      "Training 87     - 100    -          0.0014 -           1.0000    | 1.0000   - 0.1600\n",
      "\u001b[1;4mValidati 87     - 100    -          1.4840 -           0.7812    | 0.7768   - 0.0122\u001b[0m\n",
      "Training 88     - 100    -          0.0006 -           1.0000    | 1.0000   - 0.1591\n",
      "\u001b[1;4mValidati 88     - 100    -          1.5578 -           0.7812    | 0.7812   - 0.0114\u001b[0m\n",
      "Training 89     - 100    -          0.0009 -           1.0000    | 1.0000   - 0.1600\n",
      "\u001b[1;4mValidati 89     - 100    -          1.3743 -           0.8281    | 0.8281   - 0.0116\u001b[0m\n",
      "Training 90     - 100    -          0.0005 -           1.0000    | 1.0000   - 0.1590\n",
      "\u001b[1;4mValidati 90     - 100    -          1.1435 -           0.8516    | 0.8516   - 0.0115\u001b[0m\n",
      "Training 91     - 100    -          0.0008 -           1.0000    | 1.0000   - 0.1595\n",
      "\n",
      "Training 92     - 100    -          0.0011 -           1.0000    | 1.0000   - 0.1577\n",
      "\u001b[1;4mValidati 92     - 100    -          1.2161 -           0.8516    | 0.8516   - 0.0112\u001b[0m\n",
      "Training 93     - 100    -          0.0005 -           1.0000    | 1.0000   - 0.1563\n",
      "\u001b[1;4mValidati 93     - 100    -          0.8038 -           0.8516    | 0.8516   - 0.0121\u001b[0m\n",
      "Training 94     - 100    -          0.0009 -           1.0000    | 1.0000   - 0.1571\n",
      "\u001b[1;4mValidati 94     - 100    -          1.0847 -           0.8516    | 0.8516   - 0.0122\u001b[0m\n",
      "Training 95     - 100    -          0.0004 -           1.0000    | 1.0000   - 0.1574\n",
      "\u001b[1;4mValidati 95     - 100    -          0.7288 -           0.8984    | 0.8984   - 0.0120\u001b[0m\n",
      "Training 96     - 100    -          0.0003 -           1.0000    | 1.0000   - 0.1618\n",
      "\u001b[1;4mValidati 96     - 100    -          1.1549 -           0.8516    | 0.8516   - 0.0144\u001b[0m\n",
      "Training 97     - 100    -          0.0007 -           1.0000    | 1.0000   - 0.1642\n",
      "\u001b[1;4mValidati 97     - 100    -          0.7950 -           0.8750    | 0.8750   - 0.0131\u001b[0m\n",
      "Training 98     - 100    -          0.0008 -           1.0000    | 1.0000   - 0.1607\n",
      "\u001b[1;4mValidati 98     - 100    -          1.0830 -           0.8750    | 0.8750   - 0.0129\u001b[0m\n",
      "Training 99     - 100    -          0.0004 -           1.0000    | 1.0000   - 0.1602\n",
      "\n",
      "Training 100    - 100    -          0.0006 -           1.0000    | 1.0000   - 0.1597\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [-1, 128, 8, 54]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 54]               0\n",
      "           Conv2d-72           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 54]             256\n",
      "             ReLU-74           [-1, 128, 8, 54]               0\n",
      "           Conv2d-75           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 54]             256\n",
      "             ReLU-77           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 54]               0\n",
      "           Conv2d-79           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 54]             256\n",
      "             ReLU-81           [-1, 128, 8, 54]               0\n",
      "           Conv2d-82           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 54]             256\n",
      "             ReLU-84           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 54]               0\n",
      "           Conv2d-86           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 54]             256\n",
      "             ReLU-88           [-1, 128, 8, 54]               0\n",
      "           Conv2d-89           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 54]             256\n",
      "             ReLU-91           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 54]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,472,554\n",
      "Trainable params: 1,472,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 107.11\n",
      "Params size (MB): 5.62\n",
      "Estimated Total Size (MB): 112.83\n",
      "----------------------------------------------------------------\n",
      "Initialize optimizer\n",
      "Initialize callbacks\n",
      "Prepare the log system\n",
      "Prepare the checkpoint system\n",
      ">>> Trainer is ready\n",
      "\n",
      "Training 1      - 100    -          2.0911 -           0.2625    | 0.1225   - 2.0715\n",
      "\u001b[1;4mValidati 1      - 100    -          4464.2649 -           0.0859    | 0.0859   - 0.3873\u001b[0m\n",
      "Training 2      - 100    -          1.2684 -           0.4750    | 0.3565   - 0.9119\n",
      "\u001b[1;4mValidati 2      - 100    -          755.8692 -           0.1094    | 0.1094   - 0.0648\u001b[0m\n",
      "Training 3      - 100    -          0.9628 -           0.6906    | 0.5538   - 0.9059\n",
      "\u001b[1;4mValidati 3      - 100    -          37.0783 -           0.1094    | 0.1097   - 0.0612\u001b[0m\n",
      "Training 4      - 100    -          0.8335 -           0.7063    | 0.6745   - 0.9248\n",
      "\u001b[1;4mValidati 4      - 100    -          13.9376 -           0.2344    | 0.2357   - 0.0665\u001b[0m\n",
      "Training 5      - 100    -          0.8504 -           0.6969    | 0.6925   - 0.9121\n",
      "\u001b[1;4mValidati 5      - 100    -          22.9910 -           0.2188    | 0.2128   - 0.0582\u001b[0m\n",
      "Training 6      - 100    -          0.7067 -           0.7688    | 0.7752   - 0.9071\n",
      "\u001b[1;4mValidati 6      - 100    -          2.0644 -           0.4688    | 0.4583   - 0.0645\u001b[0m\n",
      "Training 7      - 100    -          0.7148 -           0.7500    | 0.7388   - 0.8134\n",
      "\u001b[1;4mValidati 7      - 100    -          1.5176 -           0.6016    | 0.6118   - 0.0538\u001b[0m\n",
      "Training 8      - 100    -          0.7624 -           0.7188    | 0.7025   - 0.8221\n",
      "\u001b[1;4mValidati 8      - 100    -          0.8077 -           0.7500    | 0.7667   - 0.0524\u001b[0m\n",
      "Training 9      - 100    -          0.6732 -           0.7719    | 0.7639   - 0.8001\n",
      "\u001b[1;4mValidati 9      - 100    -          2.7241 -           0.4531    | 0.4317   - 0.0541\u001b[0m\n",
      "Training 10     - 100    -          0.6057 -           0.7937    | 0.7731   - 0.9056\n",
      "\u001b[1;4mValidati 10     - 100    -          1.2847 -           0.6641    | 0.6256   - 0.0647\u001b[0m\n",
      "Training 11     - 100    -          0.4668 -           0.8375    | 0.8366   - 0.9371\n",
      "\u001b[1;4mValidati 11     - 100    -          1.5339 -           0.5625    | 0.5079   - 0.0628\u001b[0m\n",
      "Training 12     - 100    -          0.5224 -           0.8094    | 0.8221   - 0.9171\n",
      "\u001b[1;4mValidati 12     - 100    -          1.6578 -           0.5859    | 0.5842   - 0.0617\u001b[0m\n",
      "Training 13     - 100    -          0.4912 -           0.8562    | 0.8338   - 0.9428\n",
      "\u001b[1;4mValidati 13     - 100    -          1.8276 -           0.6172    | 0.5998   - 0.0647\u001b[0m\n",
      "Training 14     - 100    -          0.5011 -           0.8094    | 0.8108   - 0.9135\n",
      "\u001b[1;4mValidati 14     - 100    -          11.8953 -           0.3516    | 0.3211   - 0.0667\u001b[0m\n",
      "Training 15     - 100    -          0.4224 -           0.8594    | 0.8479   - 0.9325\n",
      "\u001b[1;4mValidati 15     - 100    -          2.0117 -           0.5625    | 0.5565   - 0.0675\u001b[0m\n",
      "Training 16     - 100    -          0.3907 -           0.8562    | 0.8516   - 0.9143\n",
      "\u001b[1;4mValidati 16     - 100    -          1.3672 -           0.5547    | 0.5555   - 0.0689\u001b[0m\n",
      "Training 17     - 100    -          0.3657 -           0.8688    | 0.8635   - 0.9285\n",
      "\u001b[1;4mValidati 17     - 100    -          1.0585 -           0.7188    | 0.7083   - 0.0569\u001b[0m\n",
      "Training 18     - 100    -          0.2848 -           0.9125    | 0.8991   - 0.9158\n",
      "\u001b[1;4mValidati 18     - 100    -          0.9185 -           0.8203    | 0.7770   - 0.0632\u001b[0m\n",
      "Training 19     - 100    -          0.2545 -           0.9406    | 0.9311   - 0.9131\n",
      "\u001b[1;4mValidati 19     - 100    -          1.2039 -           0.6172    | 0.5777   - 0.0583\u001b[0m\n",
      "Training 20     - 100    -          0.3070 -           0.8844    | 0.8893   - 0.9380\n",
      "\u001b[1;4mValidati 20     - 100    -          1.8093 -           0.6094    | 0.6072   - 0.0674\u001b[0m\n",
      "Training 21     - 100    -          0.2548 -           0.9156    | 0.9247   - 0.9096\n",
      "\u001b[1;4mValidati 21     - 100    -          1.2381 -           0.6875    | 0.6710   - 0.0623\u001b[0m\n",
      "Training 22     - 100    -          0.2732 -           0.8969    | 0.8949   - 0.9483\n",
      "\u001b[1;4mValidati 22     - 100    -          3.1660 -           0.6328    | 0.6317   - 0.0728\u001b[0m\n",
      "Training 23     - 100    -          0.2741 -           0.9094    | 0.9050   - 0.9269\n",
      "\u001b[1;4mValidati 23     - 100    -          0.6640 -           0.8281    | 0.8114   - 0.0576\u001b[0m\n",
      "Training 24     - 100    -          0.2315 -           0.9313    | 0.9262   - 0.9346\n",
      "\u001b[1;4mValidati 24     - 100    -          0.7764 -           0.7891    | 0.7853   - 0.0643\u001b[0m\n",
      "Training 25     - 100    -          0.2834 -           0.9156    | 0.9192   - 0.9152\n",
      "\u001b[1;4mValidati 25     - 100    -          0.4297 -           0.8359    | 0.8484   - 0.0645\u001b[0m\n",
      "Training 26     - 100    -          0.1926 -           0.9438    | 0.9413   - 0.9337\n",
      "\u001b[1;4mValidati 26     - 100    -          0.9010 -           0.7031    | 0.7120   - 0.0625\u001b[0m\n",
      "Training 27     - 100    -          0.1952 -           0.9281    | 0.9285   - 0.9179\n",
      "\u001b[1;4mValidati 27     - 100    -          0.7238 -           0.7500    | 0.7640   - 0.0646\u001b[0m\n",
      "Training 28     - 100    -          0.1585 -           0.9438    | 0.9451   - 0.9399\n",
      "\u001b[1;4mValidati 28     - 100    -          0.6732 -           0.7891    | 0.7525   - 0.0649\u001b[0m\n",
      "Training 29     - 100    -          0.2059 -           0.9375    | 0.9461   - 0.9096\n",
      "\u001b[1;4mValidati 29     - 100    -          1.2017 -           0.6406    | 0.6341   - 0.0590\u001b[0m\n",
      "Training 30     - 100    -          0.1614 -           0.9438    | 0.9526   - 0.9270\n",
      "\u001b[1;4mValidati 30     - 100    -          0.7142 -           0.7422    | 0.7682   - 0.0643\u001b[0m\n",
      "Training 31     - 100    -          0.1625 -           0.9469    | 0.9434   - 0.9519\n",
      "\u001b[1;4mValidati 31     - 100    -          0.5779 -           0.8047    | 0.8177   - 0.0614\u001b[0m\n",
      "Training 32     - 100    -          0.1316 -           0.9563    | 0.9607   - 0.9159\n",
      "\u001b[1;4mValidati 32     - 100    -          0.9260 -           0.7266    | 0.7437   - 0.0639\u001b[0m\n",
      "Training 33     - 100    -          0.1230 -           0.9656    | 0.9573   - 0.9229\n",
      "\u001b[1;4mValidati 33     - 100    -          1.1656 -           0.7812    | 0.7772   - 0.0629\u001b[0m\n",
      "Training 34     - 100    -          0.0943 -           0.9812    | 0.9828   - 0.9363\n",
      "\u001b[1;4mValidati 34     - 100    -          0.8833 -           0.7266    | 0.7366   - 0.0620\u001b[0m\n",
      "Training 35     - 100    -          0.1233 -           0.9531    | 0.9546   - 0.9077\n",
      "\u001b[1;4mValidati 35     - 100    -          1.1378 -           0.7109    | 0.6738   - 0.0605\u001b[0m\n",
      "Training 36     - 100    -          0.0822 -           0.9719    | 0.9719   - 0.9357\n",
      "\u001b[1;4mValidati 36     - 100    -          0.8517 -           0.7969    | 0.7800   - 0.0637\u001b[0m\n",
      "Training 37     - 100    -          0.1096 -           0.9688    | 0.9655   - 0.9009\n",
      "\u001b[1;4mValidati 37     - 100    -          0.5847 -           0.7969    | 0.8002   - 0.0605\u001b[0m\n",
      "Training 38     - 100    -          0.0701 -           0.9812    | 0.9795   - 0.9066\n",
      "\u001b[1;4mValidati 38     - 100    -          0.4889 -           0.8594    | 0.8548   - 0.0606\u001b[0m\n",
      "Training 39     - 100    -          0.0661 -           0.9781    | 0.9781   - 0.9009\n",
      "\u001b[1;4mValidati 39     - 100    -          0.4128 -           0.8672    | 0.8740   - 0.0645\u001b[0m\n",
      "Training 40     - 100    -          0.0566 -           0.9844    | 0.9843   - 0.9350\n",
      "\u001b[1;4mValidati 40     - 100    -          1.0103 -           0.7969    | 0.7923   - 0.0615\u001b[0m\n",
      "Training 41     - 100    -          0.0517 -           0.9875    | 0.9843   - 0.9469\n",
      "\u001b[1;4mValidati 41     - 100    -          0.7184 -           0.7656    | 0.7594   - 0.0618\u001b[0m\n",
      "Training 42     - 100    -          0.0611 -           0.9875    | 0.9875   - 0.9151\n",
      "\u001b[1;4mValidati 42     - 100    -          1.1059 -           0.6406    | 0.6594   - 0.0583\u001b[0m\n",
      "Training 43     - 100    -          0.0728 -           0.9781    | 0.9766   - 0.9348\n",
      "\u001b[1;4mValidati 43     - 100    -          0.6271 -           0.8281    | 0.8219   - 0.0779\u001b[0m\n",
      "Training 44     - 100    -          0.0700 -           0.9844    | 0.9844   - 0.9544\n",
      "\u001b[1;4mValidati 44     - 100    -          0.9441 -           0.6641    | 0.6730   - 0.0624\u001b[0m\n",
      "Training 45     - 100    -          0.0458 -           0.9844    | 0.9842   - 0.9423\n",
      "\u001b[1;4mValidati 45     - 100    -          0.7435 -           0.7812    | 0.7743   - 0.0626\u001b[0m\n",
      "Training 46     - 100    -          0.0532 -           0.9812    | 0.9812   - 0.9287\n",
      "\u001b[1;4mValidati 46     - 100    -          1.0872 -           0.7188    | 0.7328   - 0.0630\u001b[0m\n",
      "Training 47     - 100    -          0.0600 -           0.9906    | 0.9890   - 0.9293\n",
      "\u001b[1;4mValidati 47     - 100    -          0.4132 -           0.8828    | 0.8810   - 0.0608\u001b[0m\n",
      "Training 48     - 100    -          0.0470 -           0.9812    | 0.9812   - 0.9062\n",
      "\u001b[1;4mValidati 48     - 100    -          0.5653 -           0.7891    | 0.8052   - 0.0618\u001b[0m\n",
      "Training 49     - 100    -          0.0409 -           0.9938    | 0.9938   - 0.9193\n",
      "\u001b[1;4mValidati 49     - 100    -          0.5721 -           0.8516    | 0.8472   - 0.0652\u001b[0m\n",
      "Training 50     - 100    -          0.0447 -           0.9906    | 0.9906   - 0.9405\n",
      "\u001b[1;4mValidati 50     - 100    -          0.3954 -           0.8984    | 0.9018   - 0.0610\u001b[0m\n",
      "Training 51     - 100    -          0.0553 -           0.9906    | 0.9906   - 0.9225\n",
      "\u001b[1;4mValidati 51     - 100    -          0.7923 -           0.8281    | 0.8281   - 0.0632\u001b[0m\n",
      "Training 52     - 100    -          0.0714 -           0.9906    | 0.9875   - 0.8985\n",
      "\u001b[1;4mValidati 52     - 100    -          0.5436 -           0.9062    | 0.9018   - 0.0597\u001b[0m\n",
      "Training 53     - 100    -          0.0268 -           0.9938    | 0.9938   - 0.9175\n",
      "\u001b[1;4mValidati 53     - 100    -          0.7350 -           0.7812    | 0.7810   - 0.0637\u001b[0m\n",
      "Training 54     - 100    -          0.0553 -           0.9844    | 0.9844   - 0.9155\n",
      "\u001b[1;4mValidati 54     - 100    -          0.6112 -           0.8047    | 0.8047   - 0.0671\u001b[0m\n",
      "Training 55     - 100    -          0.0221 -           0.9969    | 0.9969   - 0.9443\n",
      "\u001b[1;4mValidati 55     - 100    -          0.4437 -           0.8438    | 0.8438   - 0.0611\u001b[0m\n",
      "Training 56     - 100    -          0.0272 -           0.9938    | 0.9938   - 0.9308\n",
      "\u001b[1;4mValidati 56     - 100    -          0.3814 -           0.8828    | 0.8861   - 0.0608\u001b[0m\n",
      "Training 57     - 100    -          0.0260 -           0.9938    | 0.9938   - 0.9143\n",
      "\u001b[1;4mValidati 57     - 100    -          0.4355 -           0.8516    | 0.8516   - 0.0681\u001b[0m\n",
      "Training 58     - 100    -          0.0189 -           0.9938    | 0.9938   - 0.9070\n",
      "\u001b[1;4mValidati 58     - 100    -          0.4630 -           0.9141    | 0.8979   - 0.0628\u001b[0m\n",
      "Training 59     - 100    -          0.0161 -           0.9969    | 0.9969   - 0.9162\n",
      "\u001b[1;4mValidati 59     - 100    -          0.6866 -           0.7812    | 0.7718   - 0.0686\u001b[0m\n",
      "Training 60     - 100    -          0.0151 -           0.9969    | 0.9969   - 0.9229\n",
      "\u001b[1;4mValidati 60     - 100    -          0.6874 -           0.7891    | 0.7844   - 0.0649\u001b[0m\n",
      "Training 61     - 100    -          0.0094 -           1.0000    | 1.0000   - 0.9152\n",
      "\u001b[1;4mValidati 61     - 100    -          0.3550 -           0.8516    | 0.8564   - 0.0631\u001b[0m\n",
      "Training 62     - 100    -          0.0158 -           0.9969    | 0.9969   - 0.9204\n",
      "\u001b[1;4mValidati 62     - 100    -          0.5220 -           0.8438    | 0.8417   - 0.0580\u001b[0m\n",
      "Training 63     - 100    -          0.0126 -           0.9969    | 0.9969   - 0.8229\n",
      "\u001b[1;4mValidati 63     - 100    -          0.3358 -           0.8672    | 0.8802   - 0.0750\u001b[0m\n",
      "Training 64     - 100    -          0.0067 -           1.0000    | 1.0000   - 0.9121\n",
      "\u001b[1;4mValidati 64     - 100    -          0.5661 -           0.8438    | 0.8462   - 0.0634\u001b[0m\n",
      "Training 65     - 100    -          0.0083 -           1.0000    | 1.0000   - 0.9168\n",
      "\u001b[1;4mValidati 65     - 100    -          0.4403 -           0.8672    | 0.8695   - 0.0614\u001b[0m\n",
      "Training 66     - 100    -          0.0121 -           1.0000    | 1.0000   - 0.9249\n",
      "\u001b[1;4mValidati 66     - 100    -          0.7972 -           0.7812    | 0.7829   - 0.0584\u001b[0m\n",
      "Training 67     - 100    -          0.0117 -           0.9969    | 0.9969   - 0.9266\n",
      "\u001b[1;4mValidati 67     - 100    -          0.3196 -           0.8750    | 0.8782   - 0.0613\u001b[0m\n",
      "Training 68     - 100    -          0.0083 -           1.0000    | 1.0000   - 0.8371\n",
      "\u001b[1;4mValidati 68     - 100    -          0.3451 -           0.8750    | 0.8814   - 0.0584\u001b[0m\n",
      "Training 69     - 100    -          0.0063 -           1.0000    | 1.0000   - 0.8127\n",
      "\u001b[1;4mValidati 69     - 100    -          0.5769 -           0.8125    | 0.8194   - 0.0648\u001b[0m\n",
      "Training 70     - 100    -          0.0069 -           1.0000    | 1.0000   - 0.8160\n",
      "\u001b[1;4mValidati 70     - 100    -          0.5616 -           0.8594    | 0.8479   - 0.0528\u001b[0m\n",
      "Training 71     - 100    -          0.0094 -           1.0000    | 1.0000   - 0.8034\n",
      "\u001b[1;4mValidati 71     - 100    -          0.4007 -           0.8672    | 0.8514   - 0.0541\u001b[0m\n",
      "Training 72     - 100    -          0.0120 -           1.0000    | 1.0000   - 0.8154\n",
      "\u001b[1;4mValidati 72     - 100    -          0.4678 -           0.8438    | 0.8462   - 0.0529\u001b[0m\n",
      "Training 73     - 100    -          0.0052 -           1.0000    | 1.0000   - 0.8216\n",
      "\u001b[1;4mValidati 73     - 100    -          0.4033 -           0.8750    | 0.8695   - 0.0530\u001b[0m\n",
      "Training 74     - 100    -          0.0053 -           1.0000    | 1.0000   - 0.8360\n",
      "\u001b[1;4mValidati 74     - 100    -          0.3464 -           0.8984    | 0.8768   - 0.0533\u001b[0m\n",
      "Training 75     - 100    -          0.0070 -           1.0000    | 1.0000   - 0.8021\n",
      "\u001b[1;4mValidati 75     - 100    -          0.3481 -           0.8984    | 0.8894   - 0.0531\u001b[0m\n",
      "Training 76     - 100    -          0.0069 -           1.0000    | 1.0000   - 0.8351\n",
      "\u001b[1;4mValidati 76     - 100    -          0.4793 -           0.8750    | 0.8740   - 0.0528\u001b[0m\n",
      "Training 77     - 100    -          0.0070 -           1.0000    | 1.0000   - 0.8071\n",
      "\u001b[1;4mValidati 77     - 100    -          0.4543 -           0.8750    | 0.8740   - 0.0546\u001b[0m\n",
      "Training 78     - 100    -          0.0064 -           1.0000    | 1.0000   - 0.8155\n",
      "\u001b[1;4mValidati 78     - 100    -          0.5875 -           0.8594    | 0.8695   - 0.0547\u001b[0m\n",
      "Training 79     - 100    -          0.0078 -           1.0000    | 1.0000   - 0.8620\n",
      "\u001b[1;4mValidati 79     - 100    -          0.4534 -           0.8438    | 0.8462   - 0.0565\u001b[0m\n",
      "Training 80     - 100    -          0.0036 -           1.0000    | 1.0000   - 0.9184\n",
      "\u001b[1;4mValidati 80     - 100    -          0.4525 -           0.8438    | 0.8428   - 0.0632\u001b[0m\n",
      "Training 81     - 100    -          0.0071 -           1.0000    | 1.0000   - 0.8358\n",
      "\u001b[1;4mValidati 81     - 100    -          0.6563 -           0.8203    | 0.8194   - 0.0522\u001b[0m\n",
      "Training 82     - 100    -          0.0051 -           1.0000    | 1.0000   - 0.8975\n",
      "\u001b[1;4mValidati 82     - 100    -          0.5995 -           0.8203    | 0.8280   - 0.0669\u001b[0m\n",
      "Training 83     - 100    -          0.0072 -           1.0000    | 1.0000   - 0.9047\n",
      "\u001b[1;4mValidati 83     - 100    -          0.3908 -           0.8828    | 0.8861   - 0.0550\u001b[0m\n",
      "Training 84     - 100    -          0.0086 -           1.0000    | 1.0000   - 0.9015\n",
      "\u001b[1;4mValidati 84     - 100    -          0.5953 -           0.8438    | 0.8428   - 0.0628\u001b[0m\n",
      "Training 85     - 100    -          0.0062 -           1.0000    | 1.0000   - 0.9280\n",
      "\u001b[1;4mValidati 85     - 100    -          0.4978 -           0.8594    | 0.8661   - 0.0620\u001b[0m\n",
      "Training 86     - 100    -          0.0041 -           1.0000    | 1.0000   - 0.8741\n",
      "\u001b[1;4mValidati 86     - 100    -          0.6552 -           0.8594    | 0.8768   - 0.0639\u001b[0m\n",
      "Training 87     - 100    -          0.0041 -           1.0000    | 1.0000   - 0.8428\n",
      "\u001b[1;4mValidati 87     - 100    -          0.4196 -           0.8672    | 0.8661   - 0.0593\u001b[0m\n",
      "Training 88     - 100    -          0.0059 -           1.0000    | 1.0000   - 0.8158\n",
      "\u001b[1;4mValidati 88     - 100    -          0.7359 -           0.8594    | 0.8661   - 0.0608\u001b[0m\n",
      "Training 89     - 100    -          0.0041 -           1.0000    | 1.0000   - 0.8336\n",
      "\u001b[1;4mValidati 89     - 100    -          0.3797 -           0.8828    | 0.9012   - 0.0523\u001b[0m\n",
      "Training 90     - 100    -          0.0046 -           1.0000    | 1.0000   - 0.7913\n",
      "\u001b[1;4mValidati 90     - 100    -          0.4069 -           0.8828    | 0.8894   - 0.0526\u001b[0m\n",
      "Training 91     - 100    -          0.0051 -           1.0000    | 1.0000   - 0.8721\n",
      "\u001b[1;4mValidati 91     - 100    -          0.3500 -           0.9062    | 0.9127   - 0.0630\u001b[0m\n",
      "Training 92     - 100    -          0.0065 -           1.0000    | 1.0000   - 0.8826\n",
      "\u001b[1;4mValidati 92     - 100    -          0.7219 -           0.8438    | 0.8524   - 0.0585\u001b[0m\n",
      "Training 93     - 100    -          0.0050 -           1.0000    | 1.0000   - 0.8818\n",
      "\u001b[1;4mValidati 93     - 100    -          0.6555 -           0.8672    | 0.8661   - 0.0526\u001b[0m\n",
      "Training 94     - 100    -          0.0041 -           1.0000    | 1.0000   - 0.8193\n",
      "\u001b[1;4mValidati 94     - 100    -          0.3796 -           0.8906    | 0.9012   - 0.0659\u001b[0m\n",
      "Training 95     - 100    -          0.0046 -           1.0000    | 1.0000   - 0.9447\n",
      "\u001b[1;4mValidati 95     - 100    -          0.7101 -           0.8438    | 0.8524   - 0.0629\u001b[0m\n",
      "Training 96     - 100    -          0.0042 -           1.0000    | 1.0000   - 0.8859\n",
      "\u001b[1;4mValidati 96     - 100    -          0.4738 -           0.8438    | 0.8428   - 0.0639\u001b[0m\n",
      "Training 97     - 100    -          0.0048 -           1.0000    | 1.0000   - 0.8453\n",
      "\u001b[1;4mValidati 97     - 100    -          0.4019 -           0.8906    | 0.8894   - 0.0523\u001b[0m\n",
      "Training 98     - 100    -          0.0051 -           1.0000    | 1.0000   - 0.8505\n",
      "\u001b[1;4mValidati 98     - 100    -          0.7051 -           0.8438    | 0.8524   - 0.0622\u001b[0m\n",
      "Training 99     - 100    -          0.0055 -           1.0000    | 1.0000   - 0.9082\n",
      "\u001b[1;4mValidati 99     - 100    -          0.4373 -           0.8672    | 0.8768   - 0.0593\u001b[0m\n",
      "Training 100    - 100    -          0.0045 -           1.0000    | 1.0000   - 0.8477\n"
     ]
    }
   ],
   "source": [
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [[1, 2, 3, 4],\n",
    "               [2, 3, 4, 5],\n",
    "               [3, 4, 5, 1],\n",
    "               [4, 5, 1, 2],\n",
    "               [5, 1, 2, 3]]\n",
    "val_folds = [[5], [1], [2], [3], [4]]\n",
    "\n",
    "for tf, vf in zip(train_folds, val_folds):\n",
    "    training_params[\"train_folds\"] = tf\n",
    "    training_params[\"val_folds\"] = vf\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "    trainer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SupervisedTrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23051c9f417b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervisedTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wideresnet28_2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"esc10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SupervisedTrainer' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seeds = np.random.randint(10000, size=(1))\n",
    "history = {}\n",
    "\n",
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [1, 2, 3, 4]\n",
    "val_folds = [5]\n",
    "seeds = np.random\n",
    "\n",
    "for seed in seeds:\n",
    "    training_params[\"train_folds\"] = [1, 2, 3, 4]\n",
    "    training_params[\"val_folds\"] = [5]\n",
    "    training_params[\"seed\"] = seed\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "\n",
    "    history[seed] = trainer.maximum_tracker\n",
    "    trainer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
