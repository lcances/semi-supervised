{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/samova/lcances/.miniconda3/envs/pytorch-dev/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "from typing import Union\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from torchlibrosa.augmentation import SpecAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SSL.util.model_loader import load_model\n",
    "from SSL.util.loaders import load_dataset, load_optimizer, load_callbacks, load_preprocesser\n",
    "from SSL.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from SSL.util.utils import reset_seed, get_datetime, track_maximum, DotDict\n",
    "from SSL.util.mixup import MixUpBatchShuffle\n",
    "\n",
    "from metric_utils.metrics import BinaryAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"audioset-unbalanced\", type=str)\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"wideresnet28_2\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=128, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=500_000, type=int) # nb iteration\n",
    "group_t.add_argument(\"--learning_rate\", default=0.003, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_mixup = parser.add_argument_group(\"Mixup parameters\")\n",
    "group_mixup.add_argument(\"--mixup\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_alpha\", type=float, default=0.4)\n",
    "group_mixup.add_argument(\"--mixup_max\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_label\", action=\"store_true\", default=False)\n",
    "\n",
    "group_sa = parser.add_argument_group(\"Spec augmentation\")\n",
    "group_sa.add_argument(\"--specAugment\", action=\"store_true\", default=False)\n",
    "group_sa.add_argument(\"--sa_time_drop_width\", type=int, default=32)\n",
    "group_sa.add_argument('--sa_time_stripes_num', type=int, default=1)\n",
    "group_sa.add_argument(\"--sa_freq_drop_width\", type=int, default=4)\n",
    "group_sa.add_argument(\"--sa_freq_stripes_num\", type=int, default=1)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--log_suffix\", default=\"\", type=str)\n",
    "\n",
    "parser.add_argument(\"-N\", \"--nb_gpu\", default=1, type=int)\n",
    "\n",
    "\n",
    "args = parser.parse_args(['--nb_gpu', '2'])\n",
    "\n",
    "args.tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "args.checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_config': '',\n",
       " 'dataset_root': '../datasets',\n",
       " 'dataset': 'audioset-unbalanced',\n",
       " 'model': 'wideresnet28_2',\n",
       " 'supervised_ratio': 1.0,\n",
       " 'batch_size': 128,\n",
       " 'nb_epoch': 500000,\n",
       " 'learning_rate': 0.003,\n",
       " 'resume': False,\n",
       " 'seed': 1234,\n",
       " 'mixup': False,\n",
       " 'mixup_alpha': 0.4,\n",
       " 'mixup_max': False,\n",
       " 'mixup_label': False,\n",
       " 'specAugment': False,\n",
       " 'sa_time_drop_width': 32,\n",
       " 'sa_time_stripes_num': 1,\n",
       " 'sa_freq_drop_width': 4,\n",
       " 'sa_freq_stripes_num': 1,\n",
       " 'train_folds': [1, 2, 3, 4],\n",
       " 'val_folds': [5],\n",
       " 'checkpoint_root': '../model_save/',\n",
       " 'tensorboard_root': '../tensorboard/',\n",
       " 'checkpoint_path': '../model_save/audioset-unbalanced/supervised',\n",
       " 'tensorboard_path': '../tensorboard/audioset-unbalanced/supervised',\n",
       " 'log_suffix': '',\n",
       " 'nb_gpu': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    parameters=vars(args),\n",
    "    seed = args.seed,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# from SSL.trainers.esc import SupervisedTrainer\n",
    "from SSL.trainers.trainers import Trainer\n",
    "\n",
    "class SupervisedTrainer(Trainer):\n",
    "    \n",
    "    def __init__(self, model: str, dataset: str):\n",
    "        super().__init__(model, \"supervised\", dataset)\n",
    "\n",
    "trainer = SupervisedTrainer(args.model, args.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/PyTorch/audio/torchaudio/extension/extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "trainer.load_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset\n",
      "/usr/local/PyTorch/audio/torchaudio/datasets/speechcommands.py\n",
      "______\n",
      "eva\n",
      "['eval.h5']\n",
      "______\n",
      "unb\n",
      "['unbalanced_train_part08.h5', 'unbalanced_train_part02.h5', 'unbalanced_train_part05.h5', 'unbalanced_train_part10.h5', 'unbalanced_train_part01.h5', 'unbalanced_train_part03.h5', 'unbalanced_train_part07.h5', 'unbalanced_train_part06.h5', 'unbalanced_train_part09.h5', 'unbalanced_train_part04.h5']\n",
      "Getting all target\n",
      "Sort the classes\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    \n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer.load_dataset(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 500]             288\n",
      "       BatchNorm2d-2          [-1, 32, 64, 500]              64\n",
      "              ReLU-3          [-1, 32, 64, 500]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 250]               0\n",
      "            Conv2d-5          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 250]              64\n",
      "              ReLU-7          [-1, 32, 32, 250]               0\n",
      "            Conv2d-8          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 250]              64\n",
      "             ReLU-10          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 250]               0\n",
      "           Conv2d-12          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 250]              64\n",
      "             ReLU-14          [-1, 32, 32, 250]               0\n",
      "           Conv2d-15          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 250]              64\n",
      "             ReLU-17          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 250]               0\n",
      "           Conv2d-19          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 250]              64\n",
      "             ReLU-21          [-1, 32, 32, 250]               0\n",
      "           Conv2d-22          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 250]              64\n",
      "             ReLU-24          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 250]               0\n",
      "           Conv2d-26          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 250]              64\n",
      "             ReLU-28          [-1, 32, 32, 250]               0\n",
      "           Conv2d-29          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 250]              64\n",
      "             ReLU-31          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 250]               0\n",
      "           Conv2d-33          [-1, 64, 16, 125]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 125]             128\n",
      "             ReLU-35          [-1, 64, 16, 125]               0\n",
      "           Conv2d-36          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 125]             128\n",
      "           Conv2d-38          [-1, 64, 16, 125]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 125]             128\n",
      "             ReLU-40          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 125]               0\n",
      "           Conv2d-42          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 125]             128\n",
      "             ReLU-44          [-1, 64, 16, 125]               0\n",
      "           Conv2d-45          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 125]             128\n",
      "             ReLU-47          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 125]               0\n",
      "           Conv2d-49          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 125]             128\n",
      "             ReLU-51          [-1, 64, 16, 125]               0\n",
      "           Conv2d-52          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 125]             128\n",
      "             ReLU-54          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 125]               0\n",
      "           Conv2d-56          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 125]             128\n",
      "             ReLU-58          [-1, 64, 16, 125]               0\n",
      "           Conv2d-59          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 125]             128\n",
      "             ReLU-61          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 125]               0\n",
      "           Conv2d-63           [-1, 128, 8, 63]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 63]             256\n",
      "             ReLU-65           [-1, 128, 8, 63]               0\n",
      "           Conv2d-66           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 63]             256\n",
      "           Conv2d-68           [-1, 128, 8, 63]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 63]             256\n",
      "             ReLU-70           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 63]               0\n",
      "           Conv2d-72           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 63]             256\n",
      "             ReLU-74           [-1, 128, 8, 63]               0\n",
      "           Conv2d-75           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 63]             256\n",
      "             ReLU-77           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 63]               0\n",
      "           Conv2d-79           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 63]             256\n",
      "             ReLU-81           [-1, 128, 8, 63]               0\n",
      "           Conv2d-82           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 63]             256\n",
      "             ReLU-84           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 63]               0\n",
      "           Conv2d-86           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 63]             256\n",
      "             ReLU-88           [-1, 128, 8, 63]               0\n",
      "           Conv2d-89           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 63]             256\n",
      "             ReLU-91           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 63]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                  [-1, 527]          67,983\n",
      "================================================================\n",
      "Total params: 1,538,671\n",
      "Trainable params: 1,538,671\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 124.15\n",
      "Params size (MB): 5.87\n",
      "Estimated Total Size (MB): 130.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from types import MethodType\n",
    "from torch.cuda import empty_cache\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def create_model(self, nb_gpu: int = 1):\n",
    "    print(\"Create the model\")\n",
    "    empty_cache()\n",
    "\n",
    "    model_func = load_model(self.dataset, self.model_str)\n",
    "    self.model = model_func(\n",
    "        input_shape=self.input_shape,\n",
    "        num_classes=self.num_classes,\n",
    "    )\n",
    "    self.model = self.model.cuda()\n",
    "    \n",
    "    s = summary(self.model, self.input_shape)\n",
    "    \n",
    "    if nb_gpu > 1:\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "    \n",
    "trainer.create_model = MethodType(create_model, trainer)\n",
    "trainer.create_model(args.nb_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_loss(self):\n",
    "    self.loss_ce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "trainer.init_loss = MethodType(init_loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize optimizer\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    learning_rate=args.learning_rate,\n",
    ")\n",
    "trainer.init_optimizer(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize callbacks\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    optimizer=trainer.optimizer,\n",
    ")\n",
    "trainer.init_callbacks(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare suffix\n",
    "# normale training parameters\n",
    "sufix_title = ''\n",
    "sufix_title += f'_{args.learning_rate}-lr'\n",
    "sufix_title += f'_{args.supervised_ratio}-sr'\n",
    "sufix_title += f'_{args.nb_epoch}-e'\n",
    "sufix_title += f'_{args.batch_size}-bs'\n",
    "sufix_title += f'_{args.seed}-seed'\n",
    "\n",
    "# mixup parameters\n",
    "if args.mixup:\n",
    "    sufix_title += '_mixup'\n",
    "    if args.mixup_max: sufix_title += \"-max\"\n",
    "    if args.mixup_label: sufix_title += \"-label\"\n",
    "    sufix_title += f\"-{args.mixup_alpha}-a\"\n",
    "    \n",
    "# SpecAugment parameters\n",
    "if args.specAugment:\n",
    "    sufix_title += '_specAugment'\n",
    "    sufix_title += f'-{args.sa_time_drop_width}tdw'\n",
    "    sufix_title += f'-{args.sa_time_stripes_num}tsn'\n",
    "    sufix_title += f'-{args.sa_freq_drop_width}fdw'\n",
    "    sufix_title += f'-{args.sa_freq_stripes_num}fsn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_0.003-lr_1.0-sr_500000-e_128-bs_1234-seed'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sufix_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the log system\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "\n",
    "trainer.init_logs(parameters, suffix=sufix_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the checkpoint system\n",
      "checkpoint initialise at:  /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S_0.003-lr_1.0-sr_500000-e_128-bs_1234-seed\n",
      "name:  wideresnet28_2_1.0S_0.003-lr_1.0-sr_500000-e_128-bs_1234-seed\n",
      "mode:  max\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_checkpoint(parameters, suffix=sufix_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from metric_utils.metrics import Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class MAP(Metrics):\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        super().__init__(epsilon)\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        super().__call__(y_pred, y_true)\n",
    "        aps = metrics.average_precision_score(y_true, y_pred, average=None)\n",
    "        aps = numpy.nan_to_num(aps)\n",
    "        \n",
    "        self.values.append(aps.mean())\n",
    "        return self\n",
    "\n",
    "def init_metrics(self):\n",
    "    self.metrics = DotDict(\n",
    "        fscore_fn=FScore(),\n",
    "        acc_fn=BinaryAccuracy(),\n",
    "        avg_fn=ContinueAverage(),\n",
    "        mAP_fn=MAP()\n",
    "    )\n",
    "    self.time_average_fn = ContinueAverage()\n",
    "    \n",
    "    self.maximum_tracker = track_maximum()\n",
    "\n",
    "trainer.init_metrics = MethodType(init_metrics, trainer)\n",
    "trainer.init_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_printing_form(self):\n",
    "    UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "    RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "    header_form = \"Type            Epoch -       /       - Losses: bce       - Metrics: acc         F1           mAP           - Remaining time \"\n",
    "    header_form = \"{:<16.16} {:<5.5} - {:<5.5} / {:<5.5} - {:<7.7} {:<9.9} - {:<8.8} {:<12.12} {:<12.12} {:<12.12} - {:<6.6}\"\n",
    "    value_form  = \"{:<16.16} {:<5} - {:>5} / {:<5} - {:7.7} {:<9.4f} - {:<8.8} {:<12.3e} {:<12.3e} {:<12.3e} - {:<6.4f}\"\n",
    "\n",
    "    self.header = header_form.format(\n",
    "        \".               \", \"Epoch\", \"\", \"\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1\", \"mAP\", \"Time\"\n",
    "    )\n",
    "\n",
    "    self.train_form = value_form\n",
    "    self.val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "    \n",
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init mixup and SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DropStripes(nn.Module):\n",
    "    def __init__(self, dim, drop_width, stripes_num):\n",
    "        \"\"\"Drop stripes. \n",
    "        Args:\n",
    "          dim: int, dimension along which to drop\n",
    "          drop_width: int, maximum width of stripes to drop\n",
    "          stripes_num: int, how many stripes to drop\n",
    "        \"\"\"\n",
    "        super(DropStripes, self).__init__()\n",
    "\n",
    "        assert dim in [1, 2]    # dim 2: frequency; dim 3: time\n",
    "\n",
    "        self.dim = dim\n",
    "        self.drop_width = drop_width\n",
    "        self.stripes_num = stripes_num\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"input: (batch_size, channels, time_steps, freq_bins)\"\"\"\n",
    "\n",
    "        assert input.ndimension() == 3\n",
    "\n",
    "        if self.training is False:\n",
    "            return input\n",
    "\n",
    "        else:\n",
    "            batch_size = input.shape[0]\n",
    "            total_width = input.shape[self.dim]\n",
    "\n",
    "            for n in range(batch_size):\n",
    "                self.transform_slice(input[n], total_width)\n",
    "\n",
    "            return input\n",
    "\n",
    "\n",
    "    def transform_slice(self, e, total_width):\n",
    "        \"\"\"e: (channels, time_steps, freq_bins)\"\"\"\n",
    "\n",
    "        for _ in range(self.stripes_num):\n",
    "            distance = torch.randint(low=0, high=self.drop_width, size=(1,))[0]\n",
    "            bgn = torch.randint(low=0, high=total_width - distance, size=(1,))[0]\n",
    "\n",
    "            if self.dim == 1:\n",
    "                e[bgn : bgn + distance, :] = 0\n",
    "            elif self.dim == 2:\n",
    "                e[:, bgn : bgn + distance] = 0\n",
    "\n",
    "\n",
    "class SpecAugmentation(nn.Module):\n",
    "    def __init__(self, time_drop_width, time_stripes_num, freq_drop_width, \n",
    "        freq_stripes_num):\n",
    "        \"\"\"Spec augmetation. \n",
    "        [ref] Park, D.S., Chan, W., Zhang, Y., Chiu, C.C., Zoph, B., Cubuk, E.D. \n",
    "        and Le, Q.V., 2019. Specaugment: A simple data augmentation method \n",
    "        for automatic speech recognition. arXiv preprint arXiv:1904.08779.\n",
    "        Args:\n",
    "          time_drop_width: int\n",
    "          time_stripes_num: int\n",
    "          freq_drop_width: int\n",
    "          freq_stripes_num: int\n",
    "        \"\"\"\n",
    "\n",
    "        super(SpecAugmentation, self).__init__()\n",
    "\n",
    "        self.time_dropper = DropStripes(dim=2, drop_width=time_drop_width, \n",
    "            stripes_num=time_stripes_num)\n",
    "\n",
    "        self.freq_dropper = DropStripes(dim=1, drop_width=freq_drop_width, \n",
    "            stripes_num=freq_stripes_num)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.time_dropper(input)\n",
    "        x = self.freq_dropper(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spec augmenter\n",
    "spec_augmenter = SpecAugmentation(time_drop_width=args.sa_time_drop_width,\n",
    "                                  time_stripes_num=args.sa_time_stripes_num,\n",
    "                                  freq_drop_width=args.sa_freq_drop_width,\n",
    "                                  freq_stripes_num=args.sa_freq_stripes_num)\n",
    "\n",
    "# Mixup\n",
    "mixup_fn = MixUpBatchShuffle(alpha=args.mixup_alpha, apply_max=args.mixup_max, mix_labels=args.mixup_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "batch_summed = []\n",
    "\n",
    "\n",
    "# def calc_class_dist(y):\n",
    "#     with torch.set_grad_enabled(False):\n",
    "#         summed = torch.sum(y, axis=0)\n",
    "#         summed = summed[summed > 0]\n",
    "#         if len(summed) <= 0:\n",
    "#             return False\n",
    "\n",
    "#         ratio = min(summed) / max(summed)\n",
    "#         if ratio < 0.16:\n",
    "#             return False\n",
    "        \n",
    "#         return True\n",
    "\n",
    "def train_fn(self, epoch, X, y, start_time) -> Union[float, float]:\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "\n",
    "    self.model.train()\n",
    "\n",
    "    y_ = y.detach().clone() # keep a copy outside the graph and in cpu to compute the mAP\n",
    "\n",
    "    X = X.cuda().float()\n",
    "    y = y.cuda().float()\n",
    "\n",
    "    if args.mixup:\n",
    "        X, y = mixup_fn(X, y)\n",
    "\n",
    "    if args.specAugment:\n",
    "        X = spec_augmenter(X)\n",
    "\n",
    "    logits = self.model(X)\n",
    "    loss = self.loss_ce(logits, y)\n",
    "\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        pred = torch.sigmoid(logits)\n",
    "\n",
    "        fscore = M.fscore_fn(pred, y)\n",
    "        acc = M.acc_fn(pred, y)\n",
    "        avg_ce = M.avg_fn(loss.item())\n",
    "\n",
    "        end_time = time.time()\n",
    "        running_mean_time = self.time_average_fn(end_time - start_time)\n",
    "\n",
    "        # logs\n",
    "        print(self.train_form.format(\n",
    "            \"Training: \",\n",
    "            epoch + 1,\n",
    "            e, args.nb_epoch,\n",
    "            \"\", avg_ce.mean(size=1000),\n",
    "            \"\", acc.mean(size=1000), fscore.mean(size=1000), 0.0,\n",
    "            time.time() - start_time,\n",
    "        ), end=\"\\r\")\n",
    "\n",
    "    T(\"train/Lce\", avg_ce.mean(size=1000), epoch)\n",
    "    T(\"train/f1\", fscore.mean(size=1000), epoch)\n",
    "    T(\"train/acc\", acc.mean(size=1000), epoch)\n",
    "    \n",
    "    return avg_ce.value, fscore.value\n",
    "\n",
    "trainer.train_fn = MethodType(train_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val_fn(self, epoch: int)  -> Union[float, float]:\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y = y.cuda().float()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            pred = torch.sigmoid(logits)\n",
    "            fscore = M.fscore_fn(pred, y)            \n",
    "            acc = M.acc_fn(pred, y)\n",
    "            mAP = M.mAP_fn(pred.cpu().reshape(-1), y.cpu().reshape(-1))\n",
    "            avg_ce = M.avg_fn(loss.item())\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                i, nb_batch,\n",
    "                \"\", avg_ce.mean(size=1000),\n",
    "                \"\", acc.mean(size=1000), fscore.mean(size=1000), 0.0,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"val/Lce\", avg_ce.mean(size=1000), epoch)\n",
    "    T(\"val/f1\", fscore.mean(size=1000), epoch)\n",
    "    T(\"val/acc\", acc.mean(size=1000), epoch)\n",
    "\n",
    "    T(\"hyperparameters/learning_rate\", self._get_lr(), epoch)\n",
    "\n",
    "    T(\"max/acc\", self.maximum_tracker(\"acc\", acc.mean(size=1000)), epoch)\n",
    "    T(\"max/f1\", self.maximum_tracker(\"f1\", fscore.mean(size=1000)), epoch)\n",
    "    \n",
    "    return avg_ce, fscore\n",
    "    \n",
    "trainer.val_fn = MethodType(val_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(self):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    # Load best epoch\n",
    "    self.checkpoint.load_best()\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.test_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            pred = torch.sigmoid(logits)\n",
    "            y_one_hot = y # F.one_hot(y, num_classes=self.num_classes)\n",
    "            fscore = M.fscore_fn(pred, y_one_hot).mean\n",
    "            \n",
    "            acc = M.acc_fn(logits, y).mean\n",
    "            \n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Testing: \",\n",
    "                1,\n",
    "                i, nb_batch,\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "            \n",
    "    return avg_ce, fscore\n",
    "            \n",
    "trainer.test_fn = MethodType(test_fn, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume if wish\n",
    "if args.resume:\n",
    "    trainer.checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                Epoch -       /       - Losses: ce        - metrics: acc          F1           mAP          - Time  \n",
      "Training:        10001 - 10000 / 500000 -         0.0101    -          9.977e-01    5.051e-01    0.000e+00    - 541.5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:        20001 - 20000 / 500000 -         0.0048    -          9.986e-01    6.425e-01    0.000e+00    - 1586.63404227\u001b[0m\n",
      "Training:        30001 - 30000 / 500000 -         0.0010    -          9.998e-01    8.386e-01    0.000e+00    - 2637.79088095\u001b[0m\n",
      "Training:        40001 - 40000 / 500000 -         0.0002    -          1.000e+00    8.790e-01    0.000e+00    - 3699.55829828\u001b[0m\n",
      "Training:        50001 - 50000 / 500000 -         0.0001    -          1.000e+00    8.820e-01    0.000e+00    - 4759.18136560\u001b[0m\n",
      "Training:        60001 - 60000 / 500000 -         0.0001    -          1.000e+00    8.830e-01    0.000e+00    - 5817.22918772\u001b[0m\n",
      "Training:        70001 - 70000 / 500000 -         0.0000    -          1.000e+00    8.840e-01    0.000e+00    - 6886.31809629\u001b[0m\n",
      "Training:        80001 - 80000 / 500000 -         0.0000    -          1.000e+00    8.840e-01    0.000e+00    - 7954.36931027\u001b[0m\n",
      "Training:        90001 - 90000 / 500000 -         0.0000    -          1.000e+00    8.810e-01    0.000e+00    - 9027.57993193\u001b[0m\n",
      "Training:        100001 - 100000 / 500000 -         0.0000    -          1.000e+00    8.820e-01    0.000e+00    - 10089.96143\u001b[0m\n",
      "Training:        110001 - 110000 / 500000 -         0.0000    -          1.000e+00    8.820e-01    0.000e+00    - 11161.685432\u001b[0m\n",
      "Training:        120001 - 120000 / 500000 -         0.0000    -          1.000e+00    8.830e-01    0.000e+00    - 12227.357287\u001b[0m\n",
      "Training:        130001 - 130000 / 500000 -         0.0000    -          1.000e+00    8.860e-01    0.000e+00    - 13294.180352\u001b[0m\n",
      "Training:        140001 - 140000 / 500000 -         0.0000    -          1.000e+00    8.860e-01    0.000e+00    - 14364.645009\u001b[0m\n",
      "Training:        150001 - 150000 / 500000 -         0.0000    -          1.000e+00    8.860e-01    0.000e+00    - 15435.935269\u001b[0m\n",
      "Training:        160001 - 160000 / 500000 -         0.0000    -          1.000e+00    8.870e-01    0.000e+00    - 16511.506855\u001b[0m\n",
      "Training:        170001 - 170000 / 500000 -         0.0000    -          1.000e+00    8.840e-01    0.000e+00    - 17588.989205\u001b[0m\n",
      "\u001b[1;4mValidation:      170001 -  1895 / 20352 -         0.0598    -          9.950e-01    1.158e-01    0.000e+00    - 42.9182\u001b[0m\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-579e21b497a8>\", line 17, in <module>\n",
      "    val_avg_ce, val_fscore = trainer.val_fn(e)\n",
      "  File \"<ipython-input-25-5e618d7d88eb>\", line 33, in val_fn\n",
      "    \"\", acc.mean(size=1000), fscore.mean(size=1000), 0.0,\n",
      "  File \"/users/samova/lcances/pytorch_metrics/metric_utils/metrics.py\", line 28, in mean\n",
      "    accumulate = sum(self.values[-size:])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1148, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1185, in get_records\n",
      "    traceback.print_exc(file=self.ostream)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 163, in print_exc\n",
      "    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 103, in print_exception\n",
      "    for line in TracebackException(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 509, in __init__\n",
      "    self.stack = StackSummary.extract(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 366, in extract\n",
      "    f.line\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2060, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2005, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 524, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 536, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 534, in _load_lines\n",
      "    frame.line\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-28-579e21b497a8>\", line 17, in <module>\n",
      "    val_avg_ce, val_fscore = trainer.val_fn(e)\n",
      "  File \"<ipython-input-25-5e618d7d88eb>\", line 33, in val_fn\n",
      "    \"\", acc.mean(size=1000), fscore.mean(size=1000), 0.0,\n",
      "  File \"/users/samova/lcances/pytorch_metrics/metric_utils/metrics.py\", line 28, in mean\n",
      "    accumulate = sum(self.values[-size:])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1148, in format_exception_as_a_whole\n",
      "    records = self.get_records(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1185, in get_records\n",
      "    traceback.print_exc(file=self.ostream)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 163, in print_exc\n",
      "    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 103, in print_exception\n",
      "    for line in TracebackException(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 509, in __init__\n",
      "    self.stack = StackSummary.extract(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 366, in extract\n",
      "    f.line\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2060, in showtraceback\n",
      "    print('\\n' + self.get_exception_only(), file=sys.stderr)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2005, in get_exception_only\n",
      "    msg = traceback.format_exception_only(etype, value)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 140, in format_exception_only\n",
      "    return list(TracebackException(etype, value, None).format_exception_only())\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 524, in __init__\n",
      "    self._load_lines()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 536, in _load_lines\n",
      "    self.__context__._load_lines()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 534, in _load_lines\n",
      "    frame.line\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/traceback.py\", line 288, in line\n",
      "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 16, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 394, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 363, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/tokenize.py\", line 321, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1211, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Fit function\n",
    "trainer.set_printing_form()\n",
    "print(trainer.header)\n",
    "\n",
    "start_epoch = trainer.checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "train_iterator = iter(trainer.train_loader)\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    # Perform train \n",
    "    train_avg_ce, train_fscore = trainer.train_fn(e, *train_iterator.next(), start_time)\n",
    "    \n",
    "    # Validation every 10 000 iteration\n",
    "    if e % 10_000 == 0 and e != 0:\n",
    "        val_avg_ce, val_fscore = trainer.val_fn(e)\n",
    "        trainer.checkpoint.step(val_fscore.value)\n",
    "    \n",
    "    # Apply the different callbacks\n",
    "#     for c in trainer.callbacks:\n",
    "#         c.step()\n",
    "    \n",
    "    if e % 1000 == 0:\n",
    "        trainer.tensorboard.flush()\n",
    "    \n",
    "trainer.save_hparams(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_summed_ = batch_summed.copy()\n",
    "ratio = []\n",
    "\n",
    "for i in range(len(batch_summed)):\n",
    "    batch = batch_summed_[i].cpu()\n",
    "    batch = batch[batch > 0]\n",
    "    \n",
    "    ratio.append(min(batch) / max(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0, figsize=(20,5))\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset.lower() == \"speechcommand\":\n",
    "    trainer.test_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .llll||=||llll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== wideresnet28_2 ========\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/0.5S/wideresnet28_2_0.5S.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-label-0.4-a_specAugment-32tdw-1tsn-4fdw-1fsn.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_specAugment-32tdw-1tsn-4fdw-1fsn.last\n",
      "\n",
      "======== wideresnet28_8 ========\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_8/1.0S/wideresnet28_8_1.0S.last\n",
      "\n",
      "======== MobileNetV1 ========\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/MobileNetV1/1.0S/MobileNetV1_1.0S.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/MobileNetV1/1.0S/MobileNetV1_1.0Smixup.last\n",
      "\n",
      "======== cnn14 ========\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/cnn14/1.0S/cnn14_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-max-label-1.0-a.last\n",
      "\n",
      "======== MobileNetV2 ========\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/MobileNetV2/1.0S/MobileNetV2_1.0S.last\n"
     ]
    }
   ],
   "source": [
    "path_root = '/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised'\n",
    "model_dir = os.listdir(path_root)\n",
    "\n",
    "for model in model_dir:\n",
    "    print('')\n",
    "    print('='*8, model, \"=\"*8)\n",
    "    model_path = os.path.join(path_root, model)\n",
    "    \n",
    "    ratio_dir = os.listdir(model_path)\n",
    "    for ratio in ratio_dir:\n",
    "        ratio_path = os.path.join(model_path, ratio)\n",
    "        model_list = os.listdir(ratio_path)\n",
    "        \n",
    "        for model_save in model_list:\n",
    "            final_path = os.path.join(ratio_path, model_save)\n",
    "            print('\\t', final_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2dc6a6f14f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/cnn14/1.0S/cnn14_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-max-label-1.0-a.last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/semi-supervised/SSL/util/checkpoint.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.checkpoint.load('/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/cnn14/1.0S/cnn14_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-max-label-1.0-a.last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 / 159\r"
     ]
    }
   ],
   "source": [
    "from metric_utils.metrics import Precision, Recall\n",
    "\n",
    "total_pred = []\n",
    "total_targets = []\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "nb_batch = len(trainer.val_loader)\n",
    "\n",
    "S = nn.Sigmoid()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, (X, y) in enumerate(trainer.val_loader):\n",
    "        X = X.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "\n",
    "        logits = trainer.model(X)\n",
    "        \n",
    "        total_pred.append(S(logits).cpu())\n",
    "        total_targets.append(y.cpu())\n",
    "        \n",
    "        print(\"%d / %d\" % (i, nb_batch), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_ = numpy.vstack(total_pred)\n",
    "total_targets_ = numpy.vstack(total_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20352, 159)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_targets_), len(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = metrics.average_precision_score(total_targets_, total_pred_, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005341823262602574"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_targets = numpy.vstack(total_targets)\n",
    "total_pred = numpy.vstack(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 527/527 [00:01<00:00, 281.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics_auc = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    metrics_auc.append(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51428088034538"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(metrics_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing d-prime\n",
    "https://stats.stackexchange.com/questions/492673/understanding-and-implementing-the-dprime-measure-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "Z = norm.ppf\n",
    "\n",
    "def calc_dprime(y_true, y_pred):\n",
    "    return numpy.sqrt(2) * Z(metrics.roc_auc_score(y_true,y_pred))\n",
    "\n",
    "dprimes = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    dprimes.append(calc_dprime(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.mean(dprimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `fit` function from trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.trainers import SupervisedTrainer\n",
    "\n",
    "training_params=dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    learning_rate=args.learning_rate,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    seed=args.seed,\n",
    "\n",
    ")\n",
    "other_params = dict(\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    training_params,\n",
    "    **other_params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [[1, 2, 3, 4],\n",
    "               [2, 3, 4, 5],\n",
    "               [3, 4, 5, 1],\n",
    "               [4, 5, 1, 2],\n",
    "               [5, 1, 2, 3]]\n",
    "val_folds = [[5], [1], [2], [3], [4]]\n",
    "\n",
    "for tf, vf in zip(train_folds, val_folds):\n",
    "    training_params[\"train_folds\"] = tf\n",
    "    training_params[\"val_folds\"] = vf\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "    trainer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seeds = np.random.randint(10000, size=(1))\n",
    "history = {}\n",
    "\n",
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [1, 2, 3, 4]\n",
    "val_folds = [5]\n",
    "seeds = np.random\n",
    "\n",
    "for seed in seeds:\n",
    "    training_params[\"train_folds\"] = [1, 2, 3, 4]\n",
    "    training_params[\"val_folds\"] = [5]\n",
    "    training_params[\"seed\"] = seed\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "\n",
    "    history[seed] = trainer.maximum_tracker\n",
    "    trainer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
